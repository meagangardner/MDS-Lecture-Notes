{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dsci512_header.png\" width=\"600\">\n",
    "\n",
    "# Lecture 4 Sparse matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics\n",
    "- Dask and parallelized computation on CPUs \n",
    "- Pytorch and GPU computation\n",
    "- Data types\n",
    "- Sparse matrices\n",
    "- Bag-of-word matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "- Identify situations where matrix parallelization is beneficial or necessary.\n",
    "- Apply array operations using GPUs.\n",
    "- Understand the advantages and disadvantages of different floating-point precision levels.\n",
    "- Understand sparse matrix representations.\n",
    "- Select the appropriate sparse matrix representation for different types of operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block matrix operations\n",
    "\n",
    "A block matrix is a matrix that is divided into smaller rectangular or square submatrices, which are called blocks.\n",
    "\n",
    "When doing matrix multiplication, you can split a large matrix into smaller blocks and perform operations on these blocks independently. You can get the exact same result as doing multiplication with the whole matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A^2 computed using block operations:\n",
      " [[ 90 100 110 120]\n",
      " [202 228 254 280]\n",
      " [314 356 398 440]\n",
      " [426 484 542 600]]\n",
      "\n",
      "A^2 computed using standard matrix multiplication:\n",
      " [[ 90 100 110 120]\n",
      " [202 228 254 280]\n",
      " [314 356 398 440]\n",
      " [426 484 542 600]]\n",
      "\n",
      "Are the results equivalent? True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a large matrix A\n",
    "A = np.array([[1, 2, 3, 4],\n",
    "              [5, 6, 7, 8],\n",
    "              [9, 10, 11, 12],\n",
    "              [13, 14, 15, 16]])\n",
    "\n",
    "# Partition A into four blocks\n",
    "A11 = A[:2, :2]\n",
    "A12 = A[:2, 2:]\n",
    "A21 = A[2:, :2]\n",
    "A22 = A[2:, 2:]\n",
    "\n",
    "# Compute A^2 using block matrix operations\n",
    "A_squared_block = np.block([[np.dot(A11, A11) + np.dot(A12, A21), np.dot(A11, A12) + np.dot(A12, A22)],\n",
    "                            [np.dot(A21, A11) + np.dot(A22, A21), np.dot(A21, A12) + np.dot(A22, A22)]])\n",
    "\n",
    "# Compute A^2 using standard matrix multiplication\n",
    "A_squared = np.dot(A, A)\n",
    "\n",
    "# Check if the two results are equivalent\n",
    "equivalent = np.array_equal(A_squared, A_squared_block)\n",
    "\n",
    "print(\"A^2 computed using block operations:\\n\", A_squared_block)\n",
    "print(\"\\nA^2 computed using standard matrix multiplication:\\n\", A_squared)\n",
    "print(\"\\nAre the results equivalent?\", equivalent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can utilize this nice property to speed up matrix computation. We can do operations on individual blocls means we can parallelize the operations, that is, distribute the task to individual processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dask](https://www.dask.org/) is a flexible parallel computing library for Python that is designed to scale computations across multiple cores or even distributed systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use dask, we first need to start the client. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to Start the Client. This is just for setting up dask. You need to do it once at the start of your program and ignore it afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-1e71d5ec-92fc-11ef-977c-ca2a41bcfd8c</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">4fa11e00</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 2\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 12\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 18.00 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-fea381cb-303a-4ccf-ae86-dbeebe202b4c</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:53941\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 2\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 12\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 18.00 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:53948\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 6\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:53951/status\" target=\"_blank\">http://127.0.0.1:53951/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 9.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:53944\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/hedayatzarkoob/Desktop/mds_courses/DSCI_512/DSCI_512_alg-data-struct_students/dask_tmp/dask-scratch-space/worker-e0myctyg\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:53949\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 6\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:53950/status\" target=\"_blank\">http://127.0.0.1:53950/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 9.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:53946\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/hedayatzarkoob/Desktop/mds_courses/DSCI_512/DSCI_512_alg-data-struct_students/dask_tmp/dask-scratch-space/worker-xedt_m98\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:53941' processes=2 threads=12, memory=18.00 GiB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "# set a temporary folder to store some intermediate results generated by dask.\n",
    "dask.config.set(temporary_directory='../dask_tmp')\n",
    "client = Client(n_workers=2) \n",
    "# set how many processes you want. this depends on how many cores your computer has. generally speaking, if the scale of your problem is large enough, more cores lead to better performance (assuming that your computation can be parallelized).\n",
    "client # get client information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of numpy vs. dask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hedayatzarkoob/miniforge3/lib/python3.11/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 762.94 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy time: 2.5162911415100098\n",
      "Dask time: 1.0489699840545654\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "import time\n",
    "\n",
    "# Create a large NumPy array\n",
    "numpy_array = np.random.rand(10**8)\n",
    "\n",
    "# Create a large Dask array\n",
    "# here we split the numpy array into chunks of 10**6\n",
    "dask_array = da.from_array(numpy_array, chunks=10**6).persist()\n",
    "\n",
    "# Perform a computationally intensive operation using NumPy\n",
    "def complex_operation(arr):\n",
    "    return np.sin(arr) + np.cos(arr) * np.tan(arr)\n",
    "\n",
    "start_time = time.time()\n",
    "result_numpy = complex_operation(numpy_array)\n",
    "print(\"NumPy time:\", time.time() - start_time)\n",
    "\n",
    "# Perform the same operation using Dask with parallelism\n",
    "# Dask will automatically manage the parallization on individual chunks for you\n",
    "# its syntax is almost the same as numpy\n",
    "def complex_operation_dask(arr):\n",
    "    return da.sin(arr) + da.cos(arr) * da.tan(arr)\n",
    "\n",
    "start_time = time.time()\n",
    "result_dask = complex_operation_dask(dask_array)\n",
    "result_dask = result_dask.compute()  # Compute the result in parallel. If you don't call compute(), dask will not run and nothing will be returned. This is called lazy evaluation. Remember `range(n)` in Python? \n",
    "print(\"Dask time:\", time.time() - start_time)\n",
    "\n",
    "# Compare the results\n",
    "print(np.allclose(result_numpy, result_dask))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose a different chunk size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hedayatzarkoob/miniforge3/lib/python3.11/site-packages/distributed/client.py:3361: UserWarning: Sending large graph of size 762.96 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask time: 3.376739025115967\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Create a large NumPy array\n",
    "numpy_array = np.random.rand(10**8)\n",
    "\n",
    "# Create a large Dask array\n",
    "dask_array = da.from_array(numpy_array, chunks=10**5).persist()\n",
    "\n",
    "# Perform the same operation using Dask with parallelism\n",
    "# Dask will automatically manage the parallization on individual chunks for you\n",
    "# its syntax is almost the same as numpy\n",
    "def complex_operation_dask(arr):\n",
    "    return da.sin(arr) + da.cos(arr) * da.tan(arr)\n",
    "\n",
    "start_time = time.time()\n",
    "result_dask = complex_operation_dask(dask_array)\n",
    "result_dask = result_dask.compute()  # Compute the result in parallel. If you don't call compute(), dask will not run and nothing will be returned. This is called lazy evaluation. Remember `range(n)` in Python? \n",
    "print(\"Dask time:\", time.time() - start_time)\n",
    "\n",
    "# Compare the results\n",
    "print(np.allclose(result_numpy, result_dask))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's now taking a much longer time! \n",
    "Why? \n",
    "\n",
    "There is communication overhead associated with parallelized computation. If the chunksize is small, the processing time might be overwhelmed by the time for communication between different processes, bringing no speed-up at all!\n",
    "\n",
    "Generally speaking, the chunks should be more than the number of cores you allocated (why? if you have 4 cores and split the matrix into 2 chunks, what will happen?).\n",
    "The chunks should not be too small. In this situation, the time needed to process each chunk is much less than the communication overhead across processes, such that we are spending most of our time waiting for the communication between processes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paralleling matrices across CPUs can speed up the computation. We can get even much more speed-up by using GPUs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Massively parallelized matrix operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing, originally developed by Meta AI and now part of the Linux Foundation umbrella. It is free and open-source software released under the modified BSD license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays are mainly used in typical machine learning algorithms (such as k-means or Decision Tree in scikit-learn) whereas pytorch tensors are mainly used in deep learning which requires heavy matrix computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "\n",
    "Cosine similarity measures the cosine of the angle between two non-zero vectors $a$ and $b$. It quantifies how similar the two vectors are, regardless of their magnitude (length). Because we normalize them to be length 1.\n",
    "\n",
    "$$\n",
    "sim(a,b) = \\frac{a}{||a||}\\cdot\\frac{b}{||b||} = \\frac{ab}{||a||\\cdot||b||}\n",
    "$$\n",
    "\n",
    "The value of cosine similarity ranges from -1 to 1:\n",
    " - 1 means the vectors are identical (pointing in the same direction).\n",
    " - 0 means the vectors are orthogonal (perpendicular), indicating no similarity.\n",
    " - -1 means the vectors are diametrically opposed (pointing in opposite directions).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Define the matrix sizes\n",
    "size = 500000\n",
    "num_iterations = 10\n",
    "\n",
    "# NumPy Matrix Multiplication\n",
    "a = np.random.rand(size)\n",
    "b = np.random.rand(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.99 ms ± 5.27 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    np_result = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PyTorch Matrix Multiplication\n",
    "a = torch.rand(size)\n",
    "b = torch.rand(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05 ms ± 100 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in range(num_iterations):\n",
    "    torch_result = torch.dot(a, b)/(torch.norm(a)*torch.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch isn't that fast on CPU. However, it is optimized for GPU computation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips: if you don't have a GPU on your computer, you can open this notebook on [Google Colab](https://colab.research.google.com/) and select T4 as your runtime. Then you can run you jobs on GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps' #change to CUDA is your are using an Nvidia GPU\n",
    "# PyTorch Matrix Multiplication\n",
    "a = torch.rand(size).to(device)\n",
    "b = torch.rand(size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734 μs ± 9.61 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in range(num_iterations):\n",
    "    torch_result = torch.dot(a, b)/(torch.norm(a)*torch.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a GPU? \n",
    "\n",
    "A GPU, or Graphics Processing Unit, is a special type of computer chip originally designed to handle complex tasks related to graphics and images. However, GPU's ability to handle complex matrix operations makes it possible to train neural networks like [AlexNet](https://en.wikipedia.org/wiki/AlexNet). Hence begins the neural network revolution that you and I are currently experiencing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch's significant speed advantage when using GPUs compared to CPUs is due to several key factors:\n",
    "\n",
    "- **Parallelism**: Modern GPUs are designed with thousands of cores, which allow them to perform many operations in parallel. PyTorch is capable of harnessing this parallelism, making it highly efficient for tasks like deep learning where many matrix multiplications occur simultaneously.\n",
    "\n",
    "- **Optimized Libraries**: PyTorch leverages highly optimized GPU libraries, such as NVIDIA cuBLAS and cuDNN, to accelerate mathematical operations. These libraries are finely tuned for specific GPU architectures and provide substantial speed improvements over CPU-based implementations.\n",
    "\n",
    "- **Data Transfer**: When using PyTorch on a GPU, data transfer between the CPU and GPU is typically minimized. This is achieved by loading data directly onto the GPU and keeping it there as much as possible, avoiding costly data transfers that can occur when using CPUs.\n",
    "\n",
    "\n",
    "It's important to note that not all tasks benefit equally from GPU acceleration. Simple, small-scale operations may not see a substantial speed improvement on GPUs compared to CPUs. However, for computationally intensive tasks such as deep learning, scientific simulations, and large-scale linear algebra operations, GPUs can provide orders of magnitude in performance improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch has similar operations in Numpy, but with a slightly different syntax. For example, an array in numpy is called tensor in pytorch. Below are some simple examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[[0.1047, 0.0723, 0.9731, 0.2648],\n",
      "         [0.9728, 0.1515, 0.4555, 0.0548],\n",
      "         [0.1664, 0.4687, 0.0307, 0.4851]],\n",
      "\n",
      "        [[0.1981, 0.0235, 0.7364, 0.1675],\n",
      "         [0.4887, 0.9179, 0.9276, 0.7995],\n",
      "         [0.3948, 0.0469, 0.2908, 0.3455]]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.Tensor(2, 3, 4)\n",
    "print(x)\n",
    "\n",
    "# Create a tensor from a (nested) list\n",
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "print(x)\n",
    "\n",
    "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
    "x = torch.rand(2, 3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([2, 3, 4])\n",
      "Size: torch.Size([2, 3, 4])\n",
      "Size: 2 3 4\n"
     ]
    }
   ],
   "source": [
    "shape = x.shape\n",
    "print(\"Shape:\", x.shape)\n",
    "\n",
    "size = x.size()\n",
    "print(\"Size:\", size)\n",
    "\n",
    "dim1, dim2, dim3 = x.size()\n",
    "print(\"Size:\", dim1, dim2, dim3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([1, 5, 9])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([3, 7])\n",
      "tensor([[ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(12).view(3, 4)\n",
    "print(\"X\", x)\n",
    "\n",
    "print(x[:, 1])   # Second column\n",
    "print(x[0])      # First row\n",
    "print(x[:2, -1]) # First two rows, last column\n",
    "print(x[1:3, :]) # Middle two rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6)\n",
    "x = x.view(2, 3) # view is reshape in numpy\n",
    "print(\"X\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line. \n",
    "print(\"W\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h tensor([[15, 18, 21],\n",
      "        [42, 54, 66]])\n"
     ]
    }
   ],
   "source": [
    "h = torch.matmul(x, W) # Verify the result by calculating it by hand too!\n",
    "print(\"h\", h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speeding up matrix multiplication with half-precision\n",
    "\n",
    "Note. A GPU is needed to run this experiment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computer engineering, decimal numbers like 1.0151 or 566132.8 are traditionally represented as floating point numbers. Since we can have infinitely precise numbers (think π), but limited space in which to store them, we have to make a compromise between precision (the number of decimals we can include in a number before we have to start rounding it) and size (how many bits we use to store the number).\n",
    "\n",
    "The technical standard for floating point numbers, IEEE 754 (for a deep dive I recommend the PyCon 2019 talk Floats are Friends: making the most of IEEE754.00000000000000002), sets the following standards:\n",
    "\n",
    " - `fp64`, aka double-precision or “double”, max rounding error of ~2^-52\n",
    "\n",
    " - `fp32`, aka single-precision or “single”, max rounding error of ~2^-23\n",
    "\n",
    " - `fp16`, aka half-precision or “half”, max rounding error of ~2^-10\n",
    "\n",
    "Python uses fp64 for the float type. PyTorch, which is much more memory-sensitive, uses fp32 as its default dtype instead.\n",
    "\n",
    "If we halve the precision (fp32 → fp16), we halve the time and space at the cost of precision (only if this is supported by specific hardware, i.e. GPU).\n",
    "\n",
    "It's rare that we need to do highly accurate matrix computations at scale. In fact, often we're doing some kind of machine learning, and less accurate approaches can prevent overfitting.\n",
    "\n",
    "If we accept some decrease in accuracy, then we can often increase speed by orders of magnitude (and/or decrease memory use)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example with cosine similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "# Define the matrix sizes\n",
    "size = 500000\n",
    "num_iterations = 10000\n",
    "\n",
    "# NumPy Matrix Multiplication\n",
    "a = np.random.rand(size)\n",
    "b = np.random.rand(size)\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18 s ± 160 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in range(num_iterations):\n",
    "    np_result = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b)) # this line is vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "# NumPy Matrix Multiplication\n",
    "a = np.random.rand(size).astype(np.float32)\n",
    "b = np.random.rand(size).astype(np.float32)\n",
    "print(a.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.04 s ± 65.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    np_result = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy Matrix Multiplication\n",
    "a = np.random.rand(size).astype(np.float16)\n",
    "b = np.random.rand(size).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "# for _ in range(num_iterations):\n",
    "#     np_result = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example above probably gives you a numerical error. Because low precision computation can easily lead to underflow or overflow, triggering errors. \n",
    "\n",
    " - Overflow: When numbers get too big for the computer to handle, they wrap around or behave unexpectedly.\n",
    " - Underflow: When numbers get too small, they are rounded down to zero, losing important information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how  `pytorch` does it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Set the size of the vectors to be created\n",
    "size = 500000  \n",
    "\n",
    "# Set the number of iterations \n",
    "num_iterations = 10000  \n",
    "\n",
    "# Specify the device for computation (GPU). You need this to enable GPU computation.\n",
    "device = 'mps' \n",
    "\n",
    "# Create two random vectors (arrays) using PyTorch\n",
    "a = torch.rand(size).to(device)  \n",
    "b = torch.rand(size).to(device)  \n",
    "\n",
    "\n",
    "print(a.dtype)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759 ms ± 4.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "for _ in range(num_iterations):  \n",
    "    # Calculate the cosine similarity between vectors 'a' and 'b'\n",
    "    torch_result = torch.dot(a, b) / (torch.norm(a) * torch.norm(b))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Matrix Multiplication\n",
    "a = torch.rand(size).half().to(device)\n",
    "b = torch.rand(size).half().to(device)\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751 ms ± 1.54 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in range(num_iterations):\n",
    "    torch_result = torch.dot(a, b)/(torch.norm(a)*torch.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `float16`, aslo known as half precision, can reduce the computation time/memory by half! You might not see the speed up in this example. We need a problem of bigger scale to see the actual improvement. If you increase the size or the iterations by 100 times, you should see the speed up.\n",
    "Of course, a price we must pay is the reduced precision, which makes numerical underflow and overflow more frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse matrices are a class of matrices with most of its elements being 0. \n",
    "Let's initialize a sparse matrix.  \n",
    "(Here we are initializing the graph adjcency matrix, which we will cover in week 3 on graph data structure. Here you just need to know that it is a matrix with a lot of zeros in it.  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.ladder_graph(5)\n",
    "# Return the Ladder graph of length n.\n",
    "# This is two rows of n nodes, with each pair connected by a single edge.\n",
    "am_ladder = nx.adjacency_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_array"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(am_ladder) # Compressed Sparse Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sparse matrices are a conceptual data structure like a list, dictionary, set, etc.\n",
    "- [`scipy.sparse`](https://docs.scipy.org/doc/scipy/reference/sparse.html) matrices are the standard Python implementation of this conceptual data structure, like `list`, `dict`, `set`, etc.\n",
    "- Going to that link, we can see there are many types of scipy sparse matrix.\n",
    "  - This one is a [`csr_matrix`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix)\n",
    "  - More later on these types.\n",
    "- You can convert them to numpy arrays with `toarray()`, but this is often a bad idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 1 0 0 0 0]\n",
      " [1 0 1 0 0 0 1 0 0 0]\n",
      " [0 1 0 1 0 0 0 1 0 0]\n",
      " [0 0 1 0 1 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 1 0 1 0 0]\n",
      " [0 0 1 0 0 0 1 0 1 0]\n",
      " [0 0 0 1 0 0 0 1 0 1]\n",
      " [0 0 0 0 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(am_ladder.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 1 0 0 0 0]\n",
      " [1 0 1 0 0 0 1 0 0 0]\n",
      " [0 1 0 1 0 0 0 1 0 0]\n",
      " [0 0 1 0 1 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 1 0 1 0 0]\n",
      " [0 0 1 0 0 0 1 0 1 0]\n",
      " [0 0 0 1 0 0 0 1 0 1]\n",
      " [0 0 0 0 1 0 0 0 1 0]]\n",
      "---\n",
      "[[0 1 0 0 0 1 0 0 0 0]\n",
      " [1 0 1 0 0 0 1 0 0 0]\n",
      " [0 1 0 1 0 0 0 1 0 0]\n",
      " [0 0 1 0 1 0 0 0 1 0]\n",
      " [0 0 0 1 0 0 0 0 0 1]\n",
      " [1 0 0 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 0 1 0 1 0 0]\n",
      " [0 0 1 0 0 0 1 0 1 0]\n",
      " [0 0 0 1 0 0 0 1 0 1]\n",
      " [0 0 0 0 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "A = am_ladder.toarray() # undirect graph = symmetric matrix;\n",
    "\n",
    "print(A)\n",
    "print(\"---\")\n",
    "print(A.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_array"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a bigger sparse matrix\n",
    "G = nx.fast_gnp_random_graph(100_000,1e-4) \n",
    "am = nx.adjacency_matrix(G)\n",
    "type(am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am.shape # 10 billion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998890"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am.nnz # non-zero elements of the matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stored in full form, the matrix would take up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.39 ms ± 16.3 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.sum(am, axis = 0) # column-wise sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[1 7]\n",
      "[2 6]\n",
      "[1 7]\n",
      "[2 6]\n"
     ]
    }
   ],
   "source": [
    "# https://numpy.org/doc/stable/reference/generated/numpy.sum.html\n",
    "print(np.sum([[0, 1], [2, 5]], axis=None))  # default\n",
    "\n",
    "print(np.sum([[0, 1], [2, 5]], axis=1))     # row-wise sum\n",
    "print(np.sum([[0, 1], [2, 5]], axis=0))     # column-wise sum\n",
    "\n",
    "print(np.sum([[0, 1], [2, 5]], axis=-1))     # last axis ->  row\n",
    "print(np.sum([[0, 1], [2, 5]], axis=-2))     # second last axis ->  column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The full matrix would take up 80 GB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "full_size = int(np.prod(am.shape))*8/(1e9)\n",
    "print(\"The full matrix would take up %d GB\" % full_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the array:  10000000000\n",
      "Memory size of one array element in bytes:  8\n",
      "Memory size of numpy array in bytes: 80000000000 Bytes\n",
      "Memory size of numpy array in gigabytes: 80.0 GB\n"
     ]
    }
   ],
   "source": [
    "x = am.toarray()\n",
    "\n",
    "print(\"Size of the array: \",\n",
    "      x.size)\n",
    " \n",
    "print(\"Memory size of one array element in bytes: \",\n",
    "      x.itemsize)\n",
    "\n",
    "print(\"Memory size of numpy array in bytes:\",\n",
    "      x.size * x.itemsize, \"Bytes\")\n",
    "\n",
    "print(\"Memory size of numpy array in gigabytes:\",\n",
    "      (x.size * x.itemsize) / (1e9), \"GB\")                        # 1 byte = 1e-9 gigabyte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot! How big is the sparse matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparse matrix takes up 7 NB\n"
     ]
    }
   ],
   "source": [
    "sparse_size = am.data.nbytes/1e6\n",
    "print(\"The sparse matrix takes up %d NB\" % sparse_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the fraction of space saved is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparse matrix is 10011x smaller\n"
     ]
    }
   ],
   "source": [
    "frac_nz = am.nnz / np.prod(am.shape)\n",
    "print(\"The sparse matrix is %dx smaller\" % (1/frac_nz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Right, so we definitely don't want to store the full matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regular numpy functions work on sparse matrices, although they might be fast/slow depending on various factors. \n",
    "- You definitely do not want to iterate through the rows - make sure you use built-in numpy functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse datasets\n",
    "\n",
    "Sparse matrices come up _a lot_ in practice. For example:\n",
    "\n",
    "- Word counts: we might represent a document by which words are in it, but only a small fraction of all words would appear in a given document.\n",
    "- Ratings: we might represent an Amazon item by the user ratings, but only a small fraction of all users have rated a given item.\n",
    "- Physical processes: in a 2019 Capstone project, MDS students examined images from a particle physics dataset, in which most of the sensors got zero signal.\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building sparse matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an empty sparse martrix, just provide the shape as the argument to the constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix,csc_matrix,lil_matrix\n",
    "# csr: Compressed Sparse Row array\n",
    "# csc: Compressed Sparse Column array\n",
    "# lil: Row-based list of lists sparse array\n",
    "\n",
    "shape = (10,10)\n",
    "#my code here\n",
    "x = csr_matrix(shape)\n",
    "#my code here\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " However, this is a bad way to build a sparse matrix of any significant size. In fact, scipy will warn you that it's a very bad idea to try to populate a CSR sparse matrix directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hedayatzarkoob/miniforge3/lib/python3.11/site-packages/scipy/sparse/_index.py:108: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "x[5,5] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way? Build the matrix in another sparse format, and then convert. Let build a diagonal matrix using the lil (linked list, i.e. the treasure boxes) format, which doesn't support efficient row or column operations like the csr and csc matrices, but does support efficient assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 10 stored elements and shape (10, 10)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (3, 3)\t1.0\n",
      "  (4, 4)\t1.0\n",
      "  (5, 5)\t1.0\n",
      "  (6, 6)\t1.0\n",
      "  (7, 7)\t1.0\n",
      "  (8, 8)\t1.0\n",
      "  (9, 9)\t1.0\n"
     ]
    }
   ],
   "source": [
    "#my code here\n",
    "shape = (10,10)\n",
    "\n",
    "x = lil_matrix(shape)\n",
    "for i in range(shape[0]):\n",
    "    x[i,i] = 1\n",
    "    \n",
    "x = csr_matrix(x)\n",
    "print(x)\n",
    "#my code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Scikit learn package allows you to create csr sparse matrices from Python dictionaries (using [DictVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html)) and even directly from raw text strings (using [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html);).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bar' 'baz' 'foo']\n",
      "[[2. 0. 1.]\n",
      " [0. 1. 3.]]\n",
      "<class 'numpy.ndarray'>\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "D1 = [{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}]\n",
    "X1 = dv.fit_transform(D1)\n",
    "print(dv.get_feature_names_out())\n",
    "print(X1)\n",
    "print(type(X1))\n",
    "# print(dv.vocabulary_)\n",
    "print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bar' 'baz' 'foo']\n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 8 stored elements and shape (5, 3)>\n",
      "  Coords\tValues\n",
      "  (0, 2)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 2)\t1\n",
      "  (3, 0)\t1\n",
      "  (4, 0)\t1\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[1 1 1]\n",
      " [1 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "D2 = ['foo bar baz', 'bar foo', 'foo', 'bar', 'bar']\n",
    "X2 = cv.fit_transform(D2)\n",
    "print(cv.get_feature_names_out())\n",
    "print(X2)\n",
    "print(type(X2))\n",
    "print(X2.toarray())\n",
    "# print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/hedayatzarkoob/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #pip install nltk\n",
    "import nltk\n",
    "nltk.download(\"brown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we apply the vectorizer to convert this to a csr matrix. First, initialize the vectorizer, then use its `fit_transform` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CountVectorizer()`\n",
    "\n",
    "Convert a collection of text documents to a matrix of token counts.\n",
    "\n",
    "This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer()\n",
    "count_vec_output = count_vec.fit_transform(brown.words('ca01')) \n",
    "\n",
    "# print the identified unique words along with their indices\n",
    "print(count_vec.vocabulary_['fulton'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#print(count_vec_output)\n",
    "print(type(count_vec_output))\n",
    "print(count_vec_output.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitfalls "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix vs. Array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that when you do an operation which on sparse matrix that removes one of the dimensions (as we did above), you actually don't have a sparse matrix anymore. \n",
    "- Surprisingly, you also don't have a numpy array! \n",
    "- What you have a numpy [matrix](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.html), which is distinct from an array. \n",
    "    - See [here](https://numpy.org/devdocs/user/numpy-for-matlab-users.html#array-or-matrix-which-should-i-use) for a discussion of the differences between arrays and matrices. \n",
    "- Rule of thumb: (non-sparse) matrices will cause you headaches and you should stay away from them. \n",
    "- You can access an array version of the matrix (without copying it) using `np.asarray`, and you should probably do that right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "wpt_matrix = np.matrix(np.random.rand(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.matrix"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wpt_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06923231, 0.91851702, 0.37591892, 0.48076971, 0.7422663 ,\n",
       "        0.96699858, 0.24414196, 0.32340762, 0.24895789, 0.30296409,\n",
       "        0.7675246 , 0.89395855, 0.37799328, 0.74979643, 0.13844749],\n",
       "       [0.3422048 , 0.49872977, 0.21432752, 0.51772241, 0.68127839,\n",
       "        0.40091081, 0.70660313, 0.26479628, 0.30425981, 0.95524655,\n",
       "        0.88995323, 0.26461024, 0.8264857 , 0.34009014, 0.34517586],\n",
       "       [0.97020152, 0.24784675, 0.41440296, 0.24177035, 0.13898654,\n",
       "        0.58526424, 0.95071219, 0.16084719, 0.62763114, 0.24894151,\n",
       "        0.98697413, 0.64055135, 0.21057308, 0.05069404, 0.62251933],\n",
       "       [0.06421394, 0.55711578, 0.47713244, 0.72443364, 0.43935553,\n",
       "        0.10002106, 0.32347853, 0.39863408, 0.87219439, 0.93852426,\n",
       "        0.34434528, 0.79452557, 0.26949563, 0.89001203, 0.69222248],\n",
       "       [0.07298253, 0.93544381, 0.81526366, 0.93671325, 0.3410356 ,\n",
       "        0.40413537, 0.25987851, 0.54887055, 0.86350517, 0.62090323,\n",
       "        0.51656315, 0.21397415, 0.46642738, 0.81898199, 0.18945519],\n",
       "       [0.37020914, 0.18655233, 0.75641224, 0.54300189, 0.53678969,\n",
       "        0.19369649, 0.76889943, 0.54183373, 0.2905696 , 0.05602051,\n",
       "        0.9707123 , 0.0311946 , 0.05936341, 0.15316907, 0.19877285],\n",
       "       [0.77942794, 0.96530404, 0.21881053, 0.50758767, 0.18766242,\n",
       "        0.16562541, 0.25018867, 0.95143982, 0.60329342, 0.00956355,\n",
       "        0.33572899, 0.91329823, 0.35888087, 0.03780412, 0.46525093],\n",
       "       [0.18600424, 0.42156861, 0.15573973, 0.95937243, 0.69205964,\n",
       "        0.19180813, 0.15949234, 0.90511197, 0.86248775, 0.28810767,\n",
       "        0.94011304, 0.065426  , 0.33331434, 0.71084201, 0.06827596],\n",
       "       [0.79601779, 0.72970918, 0.74948884, 0.6168198 , 0.3520926 ,\n",
       "        0.43609863, 0.1357824 , 0.42683319, 0.18589867, 0.00361196,\n",
       "        0.78111018, 0.62216343, 0.46151955, 0.01479854, 0.56409479],\n",
       "       [0.33375956, 0.75712608, 0.67368419, 0.46248264, 0.89842673,\n",
       "        0.72687339, 0.05634948, 0.32491033, 0.43296749, 0.60256294,\n",
       "        0.69605872, 0.86279083, 0.05119381, 0.21428457, 0.6969406 ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpt_array = np.asarray(wpt_matrix)\n",
    "wpt_array[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of where a numpy matrix will cause you trouble: operations like `flatten` (which is suppose to reduce a dataset to 1 dimension) won't work properly with a matrix, which is *always* 2-d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.06923231, 0.91851702, 0.37591892, 0.48076971, 0.7422663 ,\n",
       "         0.96699858, 0.24414196, 0.32340762, 0.24895789, 0.30296409,\n",
       "         0.7675246 , 0.89395855, 0.37799328, 0.74979643, 0.13844749,\n",
       "         0.3422048 , 0.49872977, 0.21432752, 0.51772241, 0.68127839,\n",
       "         0.40091081, 0.70660313, 0.26479628, 0.30425981, 0.95524655,\n",
       "         0.88995323, 0.26461024, 0.8264857 , 0.34009014, 0.34517586,\n",
       "         0.97020152, 0.24784675, 0.41440296, 0.24177035, 0.13898654,\n",
       "         0.58526424, 0.95071219, 0.16084719, 0.62763114, 0.24894151,\n",
       "         0.98697413, 0.64055135, 0.21057308, 0.05069404, 0.62251933,\n",
       "         0.06421394, 0.55711578, 0.47713244, 0.72443364, 0.43935553,\n",
       "         0.10002106, 0.32347853, 0.39863408, 0.87219439, 0.93852426,\n",
       "         0.34434528, 0.79452557, 0.26949563, 0.89001203, 0.69222248,\n",
       "         0.07298253, 0.93544381, 0.81526366, 0.93671325, 0.3410356 ,\n",
       "         0.40413537, 0.25987851, 0.54887055, 0.86350517, 0.62090323,\n",
       "         0.51656315, 0.21397415, 0.46642738, 0.81898199, 0.18945519,\n",
       "         0.37020914, 0.18655233, 0.75641224, 0.54300189, 0.53678969,\n",
       "         0.19369649, 0.76889943, 0.54183373, 0.2905696 , 0.05602051,\n",
       "         0.9707123 , 0.0311946 , 0.05936341, 0.15316907, 0.19877285,\n",
       "         0.77942794, 0.96530404, 0.21881053, 0.50758767, 0.18766242,\n",
       "         0.16562541, 0.25018867, 0.95143982, 0.60329342, 0.00956355,\n",
       "         0.33572899, 0.91329823, 0.35888087, 0.03780412, 0.46525093,\n",
       "         0.18600424, 0.42156861, 0.15573973, 0.95937243, 0.69205964,\n",
       "         0.19180813, 0.15949234, 0.90511197, 0.86248775, 0.28810767,\n",
       "         0.94011304, 0.065426  , 0.33331434, 0.71084201, 0.06827596,\n",
       "         0.79601779, 0.72970918, 0.74948884, 0.6168198 , 0.3520926 ,\n",
       "         0.43609863, 0.1357824 , 0.42683319, 0.18589867, 0.00361196,\n",
       "         0.78111018, 0.62216343, 0.46151955, 0.01479854, 0.56409479,\n",
       "         0.33375956, 0.75712608, 0.67368419, 0.46248264, 0.89842673,\n",
       "         0.72687339, 0.05634948, 0.32491033, 0.43296749, 0.60256294,\n",
       "         0.69605872, 0.86279083, 0.05119381, 0.21428457, 0.6969406 ,\n",
       "         0.24305659, 0.8527706 , 0.11678966, 0.49563005, 0.88045105,\n",
       "         0.86963136, 0.13846179, 0.78259563, 0.85878384, 0.0070805 ,\n",
       "         0.3388426 , 0.54501452, 0.12454609, 0.49316088, 0.59059898,\n",
       "         0.85840092, 0.49081242, 0.7259451 , 0.45315222, 0.56129137,\n",
       "         0.48062699, 0.78491361, 0.26271677, 0.82937967, 0.71151765,\n",
       "         0.0625318 , 0.90609356, 0.3307048 , 0.5001077 , 0.35565968,\n",
       "         0.12086803, 0.68655967, 0.52317783, 0.16621209, 0.99701509,\n",
       "         0.51957086, 0.7145493 , 0.97785203, 0.82931251, 0.30526969,\n",
       "         0.15485402, 0.99227111, 0.8296711 , 0.01587383, 0.38745313,\n",
       "         0.70700646, 0.03833806, 0.72663521, 0.67028374, 0.91222049,\n",
       "         0.24956731, 0.79505933, 0.9189898 , 0.0361318 , 0.42807731,\n",
       "         0.10285553, 0.76520361, 0.58620779, 0.07822476, 0.859025  ,\n",
       "         0.76728033, 0.53862148, 0.13706987, 0.46528487, 0.88195847,\n",
       "         0.35157164, 0.19156709, 0.23071585, 0.99137353, 0.73604717,\n",
       "         0.11326871, 0.13739764, 0.70277018, 0.76862078, 0.577464  ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpt_matrix.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this will work fine with the array version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06923231, 0.91851702, 0.37591892, 0.48076971, 0.7422663 ,\n",
       "       0.96699858, 0.24414196, 0.32340762, 0.24895789, 0.30296409,\n",
       "       0.7675246 , 0.89395855, 0.37799328, 0.74979643, 0.13844749,\n",
       "       0.3422048 , 0.49872977, 0.21432752, 0.51772241, 0.68127839,\n",
       "       0.40091081, 0.70660313, 0.26479628, 0.30425981, 0.95524655,\n",
       "       0.88995323, 0.26461024, 0.8264857 , 0.34009014, 0.34517586,\n",
       "       0.97020152, 0.24784675, 0.41440296, 0.24177035, 0.13898654,\n",
       "       0.58526424, 0.95071219, 0.16084719, 0.62763114, 0.24894151,\n",
       "       0.98697413, 0.64055135, 0.21057308, 0.05069404, 0.62251933,\n",
       "       0.06421394, 0.55711578, 0.47713244, 0.72443364, 0.43935553,\n",
       "       0.10002106, 0.32347853, 0.39863408, 0.87219439, 0.93852426,\n",
       "       0.34434528, 0.79452557, 0.26949563, 0.89001203, 0.69222248,\n",
       "       0.07298253, 0.93544381, 0.81526366, 0.93671325, 0.3410356 ,\n",
       "       0.40413537, 0.25987851, 0.54887055, 0.86350517, 0.62090323,\n",
       "       0.51656315, 0.21397415, 0.46642738, 0.81898199, 0.18945519,\n",
       "       0.37020914, 0.18655233, 0.75641224, 0.54300189, 0.53678969,\n",
       "       0.19369649, 0.76889943, 0.54183373, 0.2905696 , 0.05602051,\n",
       "       0.9707123 , 0.0311946 , 0.05936341, 0.15316907, 0.19877285,\n",
       "       0.77942794, 0.96530404, 0.21881053, 0.50758767, 0.18766242,\n",
       "       0.16562541, 0.25018867, 0.95143982, 0.60329342, 0.00956355,\n",
       "       0.33572899, 0.91329823, 0.35888087, 0.03780412, 0.46525093,\n",
       "       0.18600424, 0.42156861, 0.15573973, 0.95937243, 0.69205964,\n",
       "       0.19180813, 0.15949234, 0.90511197, 0.86248775, 0.28810767,\n",
       "       0.94011304, 0.065426  , 0.33331434, 0.71084201, 0.06827596,\n",
       "       0.79601779, 0.72970918, 0.74948884, 0.6168198 , 0.3520926 ,\n",
       "       0.43609863, 0.1357824 , 0.42683319, 0.18589867, 0.00361196,\n",
       "       0.78111018, 0.62216343, 0.46151955, 0.01479854, 0.56409479,\n",
       "       0.33375956, 0.75712608, 0.67368419, 0.46248264, 0.89842673,\n",
       "       0.72687339, 0.05634948, 0.32491033, 0.43296749, 0.60256294,\n",
       "       0.69605872, 0.86279083, 0.05119381, 0.21428457, 0.6969406 ,\n",
       "       0.24305659, 0.8527706 , 0.11678966, 0.49563005, 0.88045105,\n",
       "       0.86963136, 0.13846179, 0.78259563, 0.85878384, 0.0070805 ,\n",
       "       0.3388426 , 0.54501452, 0.12454609, 0.49316088, 0.59059898,\n",
       "       0.85840092, 0.49081242, 0.7259451 , 0.45315222, 0.56129137,\n",
       "       0.48062699, 0.78491361, 0.26271677, 0.82937967, 0.71151765,\n",
       "       0.0625318 , 0.90609356, 0.3307048 , 0.5001077 , 0.35565968,\n",
       "       0.12086803, 0.68655967, 0.52317783, 0.16621209, 0.99701509,\n",
       "       0.51957086, 0.7145493 , 0.97785203, 0.82931251, 0.30526969,\n",
       "       0.15485402, 0.99227111, 0.8296711 , 0.01587383, 0.38745313,\n",
       "       0.70700646, 0.03833806, 0.72663521, 0.67028374, 0.91222049,\n",
       "       0.24956731, 0.79505933, 0.9189898 , 0.0361318 , 0.42807731,\n",
       "       0.10285553, 0.76520361, 0.58620779, 0.07822476, 0.859025  ,\n",
       "       0.76728033, 0.53862148, 0.13706987, 0.46528487, 0.88195847,\n",
       "       0.35157164, 0.19156709, 0.23071585, 0.99137353, 0.73604717,\n",
       "       0.11326871, 0.13739764, 0.70277018, 0.76862078, 0.577464  ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpt_array.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another issue with sparse matrices is indexing. With a regular numpy array, `x[i,j]` and `x[i][j]` are equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41118731521740703"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41118731521740703"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because `x[1]` returns the first row, and then the `[2]` indexes into that row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48802204, 0.8551031 , 0.41118732, 0.12974941, 0.84005109,\n",
       "       0.4861311 , 0.56041248, 0.62394123, 0.62505716, 0.33407994])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41118731521740703"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_1 = x[1]\n",
    "row_1[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, with `scipy.sparse` matrices, things are a bit different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sparse = csr_matrix(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41118731521740703"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sparse[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "row index (2) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx_sparse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.11/site-packages/scipy/sparse/_csr.py:24\u001b[0m, in \u001b[0;36m_csr_base.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     27\u001b[0m         key \u001b[38;5;241m=\u001b[39m key[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.11/site-packages/scipy/sparse/_index.py:52\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 52\u001b[0m     row, col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# Dispatch to specialized methods.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row, INT_TYPES):\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.11/site-packages/scipy/sparse/_index.py:180\u001b[0m, in \u001b[0;36mIndexMixin._validate_indices\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    178\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mM \u001b[38;5;129;01mor\u001b[39;00m row \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m M:\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrow index (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) out of range\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m row)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    182\u001b[0m     row \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m M\n",
      "\u001b[0;31mIndexError\u001b[0m: row index (2) out of range"
     ]
    }
   ],
   "source": [
    "x_sparse[1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_1_sparse = x_sparse[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_1_sparse.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The sparse matrix returns a different shape.\n",
    "- This is because sparse matrices must always be 2d (same problem as non-sparse matrices)\n",
    "- In general, use the `x[1,2]` notation when possible because chaining the `[]` can be problematic in several places (e.g., also pandas).\n",
    "- However, **this is only for numpy**, not, say, a list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [[1,2,3],[4,5,6],[7,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlst\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "lst[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rows versus columns operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, you should avoid looping directly through sparse matrices.\n",
    "\n",
    "But if you do need to, you need to be very sensitive to the difference between Row (CSR) and Column (CSC) sparse matricies. \n",
    "\n",
    "Note. CSR (Compressed Sparse Row) and CSC (Compressed Sparse Column) are two common formats for storing sparse matrices. Here’s a breakdown of the differences:\n",
    "\n",
    "| Feature               | CSR                          | CSC                          |\n",
    "|----------------------|------------------------------|------------------------------|\n",
    "| Storage Arrays       | Values, Column Indices, Row Pointers | Values, Row Indices, Column Pointers |\n",
    "| Optimized For        | Row operations               | Column operations             |\n",
    "| Access Pattern       | Fast row slicing             | Fast column slicing           |\n",
    "| Use Cases            | Matrix-vector multiplication, row-wise operations | Column-wise computations, matrix factorization |\n",
    "\n",
    "You should not use CSR matrices for operations which require looping over columns. Observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = scipy.sparse.random(10000, 10000, density=0.2, format=\"csr\", random_state=321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_cols = am.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 20000000 stored elements and shape (10000, 10000)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.48 ms ± 59.3 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "(np.sum(am, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8 ms ± 61 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "(np.sum(am, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1 \n",
    "\n",
    "# iterate through the rows - this is much slower than numpy functions\n",
    "for i in range(num_rows):\n",
    "    am[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -r1 -n1\n",
    "\n",
    "# # iterate through the columns - this is much MUCH slower\n",
    "# for i in range(num_cols):\n",
    "#     am[:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above: \n",
    "\n",
    "- Looping is slower, as per usual.\n",
    "- But at least looping through the rows of a `csr_matrix` isn't that bad.\n",
    "- However, looping through the columns of a `csr_matrix` is a disaster - it took several min on my laptop!!\n",
    "  - Because it is stored _row by row_. \n",
    "  - To grab a single column, it needs to loop through each row and look for items in that column.\n",
    "- If you want to loop through columns you should first convert the matrix type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_csc = am.tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "\n",
    "for i in range(num_cols):\n",
    "    am_csc[:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Einstein Summation (einsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Einstein summation convention is the ultimate generalization of products such as matrix multiplication to multiple dimensions. It offers a compact and elegant way of specifying almost any product of scalars/vectors/matrices/tensors. Despite its generality, it can reduce the number of errors made by computer scientists and reduce the time they spend reasoning about linear algebra. It does so by being simultaneously clearer, more explicit, more self-documenting, more declarative in style and less cognitively burdensome to use. Its advantages over such things as matrix multiplication are that it liberates its user from having to think about:\n",
    "\n",
    "- The correct order in which to supply the argument tensors\n",
    "- The correct transpositions to apply to the argument tensors\n",
    "- nsuring that the correct tensor dimensions are lined up with one another\n",
    "- The correct transposition to apply to the resulting tensor\n",
    "\n",
    "\n",
    "The only things it requires are knowledge of:\n",
    "\n",
    "- Along which dimensions to compute (inner/element-wise/outer) products.\n",
    "- The desired output shape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[EINSUM IS ALL YOU NEED - EINSTEIN SUMMATION IN DEEP LEARNING](https://rockt.github.io/2018/04/30/einsum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
