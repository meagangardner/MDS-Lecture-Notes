{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab4.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Functions, Classes and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run this cell\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #pandas can get pretty verbose!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Quality\n",
    "rubric={quality:5}\n",
    "\n",
    "The code that you write for this assignment will be given one overall grade for code quality, see our code quality rubric as a guide to what we are looking for. Also, for this course (and other MDS courses that use R), we are trying to follow the PEP 8 code style. There is a guide you can refer too: https://peps.python.org/pep-0008/\n",
    "\n",
    "Each code question will also be assessed for code accuracy (i.e., does it do what it is supposed to do?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTRODUCTION\n",
    "\n",
    "In this lab, you'll be looking at a dataset called MASSIVE which contains ~1M sentences across 50 languages. It is a \"parallel corpus\", meaning that the same sentences appear in all languages. Two sentences with the same ID in different languages can be considered 'translations' of each other. (Strictly speaking they are not, they are each translations of the English sentence with that ID, but we can ignore that nuance for today.) \n",
    "\n",
    "Sentences are referred to as \"utterances\" in the context of MASSIVE, and they represent things that people would say to virtual assistants, such as \"set an alarm\", \"remind me to water my plants\", \"what time is my next appointment\", etc. Utterances are available as plain text, or with semantic annotation.\n",
    "\n",
    "You can examine the full dataset on HuggingFace here: https://huggingface.co/datasets/AmazonScience/massive\n",
    "\n",
    "To keep things manageable for the lab, we are using a slim version of MASSIVE consisting of just 5 languages with 600 utterances each: English, French, German, Korean, and Vietnamese. The data is available in 5 files named \"{language}_massive_data.csv\". For example you can load the English data like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell\n",
    "english = pd.read_csv('english_massive_data.csv', encoding='utf-8')\n",
    "english.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each language file has the same 7 columns:\n",
    "- `language` is the name of a language\n",
    "- `split` Each language is split into 'train', 'test', and 'validation' sets. An utterance will only appear in one of these sets.\n",
    "- `id` is an utterance id. Within a language, each utterance has a unique id. Across languages, utterances will have the same id if they are 'translations' of each other.\n",
    "- `utt` Raw text of an utterance, written in the conventional orthography of a language\n",
    "- `annot_utt` An annotated version of the utterance, where some words may have semantic labels indicated by square brackets\n",
    "- `scenario` The general topic of the sentence (news, alarms, music, datetime, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: get_massive_data()\n",
    "rubric={autograde:12}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6cd0b7f72a4c69db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Description\n",
    "\n",
    "Your first task is to write a new function that takes list of language names, and returns a single pandas dataframe with all the relevant data from the CSV files. Someone would be able to call your function like this:\n",
    "\n",
    "`massive = get_massive_data(languages=['English', 'French'], split='test')`\n",
    "\n",
    "Don't forget to write a docstring, explaining what your function does!\n",
    "\n",
    "### Signature\n",
    "\n",
    "`get_massive_data(languages: list, split_type: str) -> pandas.DataFrame`\n",
    "\n",
    "### Arguments\n",
    "\n",
    "`languages` is a list of languages. This argument is required and should not have a default value. \n",
    "\n",
    "`split_type` Options are 'test', 'train', 'validation', or 'all'. This argument is optional, and the default value should be 'all'.\n",
    "\n",
    "### Return value\n",
    "The function should return a pandas DataFrame. Use the utterance id as your index. Note that this will create non-unique indexes, since the same id values are used across languages.  Be sure to convert the id to an integer! \n",
    "\n",
    "The DataFrame should have these columns:\n",
    "\n",
    "<table>\n",
    "<tr><td>'language'</td>\t    <td>the name of a language (passed as part of the `languages` argument in this function)</td></tr>\n",
    "<tr><td>'text'</td>\t \t    <td>a natural language sentence (corresponds to the 'utt' column in MASSIVE)</td></tr>\n",
    "<tr><td>'annotation'</td> \t<td>the same sentence with semantic labelling on words (corresponds to the 'annot_utt' column in MASSIVE)</td></tr>\n",
    "<tr><td>'scenario'</td>\t    <td>a semantic label for a scenario (corresponds to 'scenario' column in MASSIVE)</td></tr>\n",
    "</table>\n",
    "\n",
    "For example, with English, French and German loaded, index 0 looks like this.\n",
    "<table>\n",
    "<tr><th>id</th>\t<th>language</th>\t<th>text</th>\t<th>annotation</th>\t<th>scenario</th></tr>\n",
    "\t\t\t\n",
    "<tr><td>0</td>\t<td>en-US</td>\t<td>wake me up at five am this week</td>\t<td>wake me up at [time : five am] [date : this week]</td>\t<td>alarm</td></tr>\n",
    "<tr><td>0</td>\t<td>fr-FR</td>\t<td>réveille-moi à cinq heures du matin cette semaine</td>\t<td>réveille-moi à [time : cinq heures du matin]</td> <td>alarm</td></tr>\n",
    "<tr><td>0</td>\t<td>de-DE</td>\t<td>wecke mich in dieser woche um fünf uhr auf</td>\t<td>wecke mich in [date : dieser woche] um [time :...</td>\t<td>alarm</td></tr>\n",
    "</table>\n",
    "\n",
    "### Hint\n",
    "Write a loop to load each dataset individually and then use panda's concatenate function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Exercise 1.2: error handling for `get_massive_data()`\n",
    "rubric={accuracy: 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Add code to the `get_massive_data()` function to handle incorrect language inputs, like 'zz-BB' or 'Navajo'. If a language name is not recognized, then the function should \"fail gracefully\". This means that instead of raising an error and stopping, it should skip over the incorrect name and keep processing the rest of the list. Before returning, your function should print a warning that contains all the languages that didn't work correctly. You can simply print this warning to screen with `print()`, you do not need to raise an actual Python Warning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELPER CELL\n",
    "#If you were not able to complete Exercise 1, then you can use the following function as a replacement for the rest of the lab. \n",
    "#Just uncomment the code and run the cell.\n",
    "#It returns a correctly formatted DataFrame object that you can use. \n",
    "#Note that it only returns 3 languages: English, French, and German. This is enough to pass all subsequent exercises.\n",
    "\n",
    "# import pickle\n",
    "# def get_massive_data(languages, split):\n",
    "#     with open('massive_dataframe.pkl', mode='rb') as f:\n",
    "#         massive = pickle.load(f)\n",
    "#     return massive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: get_translations()\n",
    "rubric={autograde:12}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Description\n",
    "Now that you have MASSIVE formated as a dataframe, your next task is to write a search function that takes an utterance id, and returns all the translations of that utterance. For example, to get the translations for utterance 17 we could do this:\n",
    "\n",
    "```\n",
    "languages = ['English', 'Korean']\n",
    "massive = get_massive_data(languages)\n",
    "utterance_17 = get_translations(massive, 17)\n",
    "```\n",
    "\n",
    "Don't forget to add a docstring to this function, explaining what it does.\n",
    "\n",
    "### Signature\n",
    "\n",
    "`get_translations(massive: pd.DataFrame, utterance_id: int, annotations: bool) -> pandas.DataFrame`\n",
    "\n",
    "### Arguments\n",
    "\n",
    "`massive` is a DataFrame containing MASSIVE data. Ideally this should be the output of your `get_massive_data` function. However, if you were unable to pass all of the tests, you can run the \"helper cell\" below which get a properly formatted DataFrame for you.\n",
    "\n",
    "`utterance_id` is an integer representing an utterance id\n",
    "\n",
    "`annotations` is a boolean. If True, the function return values from the 'annotations' column, if False then it return values from the 'text' column. The default is False.\n",
    "\n",
    "### Return value\n",
    "This returns a DataFrame where rows are indexed by language, and there is one column called either 'text' or 'annotation' (depending on the argument supplied to the function).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 2.1: error handling for get_translations()\n",
    "rubric = {accuracy: 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Update the `get_translations()` function to handle invalid utterance IDs. If an invalid ID is passed, then the function should return an empty dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 3: get_slot_translations()\n",
    "rubric={autograder:12}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Description\n",
    "The utterances in MASSIVE have two kinds of semantic labels: a \"scenario\", which is the general topic of the whole utterance, and \"slots\", which are specific words or phrases. Scenarios have their own column in the data. Slots have to be extracted from the text in the \"annotations\" column, where are they are indicated by square brackets.\n",
    "\n",
    "For example, utterance 7 in the 'audio' scenario has this annotation:\n",
    "\n",
    "`pause for [time : ten seconds]\t`\n",
    "\n",
    "This means the slot named 'time' has a value of 'ten seconds'. The slot names are always in English. Utterance 7 in fr-FR is annotated like this:\n",
    "\n",
    "`pause pendant [time : dix secondes]`\n",
    "\n",
    "For this exercise, you'll write a function that takes a scenario as input, and returns a table of translations for each slot in each utterance in that scenario. Extracting the slot values requires using regular expressions, which we didn't cover during class, so the code for creating a `slot_name` and `slot_value` column is included in the solution for you. \n",
    "\n",
    "Someone would be able to use your function like this:\n",
    "\n",
    "```\n",
    "massive = get_massive_data(['English', 'French'])\n",
    "audio_slots = get_slot_translations(massive, 'audio')\n",
    "```\n",
    "\n",
    "Don't forget to add a docstring to your function, explaining what it does.\n",
    "\n",
    "### Signature\n",
    "`get_slot_translations(massive: pd.DataFrame, scenario: str) -> pd.DataFrame`\n",
    "\n",
    "\n",
    "### Arguments\n",
    "`massive` a pandas dataframe with MASSIVE data. Required, no default value.\n",
    "\n",
    "`scenario` a string representing one of the scenarios in MASSIVE. Required, no default value.\n",
    "\n",
    "### Return value\n",
    "A dataframe indexed by utterance id. The first column is called 'slot_name', and the remaining columns show translations of that slot for each language passed into the function. Some utterances in MASSIVE don't have any slots. Fill any missing values with the string 'no slots'. \n",
    "\n",
    "For example, if this function were called with the English, French and German languages in the 'calendar' scenario, the head of the output table would look like this:\n",
    "\n",
    "<table>\n",
    "    <tr><th>id</th><th>slot_name</th><th>English</th><th>French</th><th>German</th></tr>\n",
    "    <tr><td>33</td><td>no slots</td><td>no slots</td><td>no slots</td><td>no slots</td></tr>\n",
    "    <tr><td>1137</td><td>time</td><td>day</td><td>journée</td><td>tag</td></tr>\n",
    "    <tr><td>1274</td><td>event_name</td><td>meeting</td><td>réunion</td><td>meeting</td></tr>\n",
    "    <tr><td>2042</td><td>event_name</td><td>meeting</td><td>réunion</td><td>besprechung</td></tr>\n",
    "</table>\n",
    "\n",
    "### Hint\n",
    "There is already code provided for you to add the `slot_value` and `slot_name` columns to your table. You need to reshape the data into the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_slot_translations(massive, scenario_name):\n",
    "  #---Don't delete these line! This code finds the necessary slots for you and adds them to the dataframe\n",
    "  pattern = r'\\[([^:\\[\\]]+) : ([^\\[\\]]+)\\]' \n",
    "  massive[['slot_name', 'slot_value']] = massive['annotation'].str.extract(pattern) \n",
    "  #---\n",
    "  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Massive class\n",
    "rubric={autograder:10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "One thing that's a little awkward about our functions so far is that we have to \"repeat\" the massive variable and pass it around\n",
    "\n",
    "```\n",
    "massive = get_massive_data(['Korean', 'German'], split='test')\n",
    "utt_123 = get_translations(massive, 123)\n",
    "weather_slots = get_slot_translations(massive, 'weather')\n",
    "```\n",
    "\n",
    "For this last exercise, you'll define a Massive object, which contains all these functions, and which can remember the languages. The code above would run this like this instead:\n",
    "\n",
    "```\n",
    "massive = Massive(['Korean', 'German'], split='test')\n",
    "utt_123 = massive.get_translations(123)\n",
    "weather_slots = massive.get_slot_translation('weather')\n",
    "```\n",
    "\n",
    "Don't worry if you didn't pass all the tests in earlier exercises. Your grade in this section depends on your ablity to organize code into a class, and you won't be double-graded on the output of any previous function.\n",
    "\n",
    "Don't forget to add a doctstring to your class, explaining what it does, and listing out methods and attributes.\n",
    "\n",
    "### Instance attributes\n",
    "\n",
    "`.languages` A list of strings representing language names\n",
    "\n",
    "`.split` One of 'test', 'train', 'validation', 'all'\n",
    "\n",
    "`.data`  A pandas dataframe\n",
    "\n",
    "### Class attributes\n",
    "\n",
    "`.all_languages` A list of strings representing all languages for which we have data\n",
    "\n",
    "### Methods\n",
    "\n",
    "`get_translations()` Takes an utterance id and 'annotations' boolean as input (as in Exercise 2).\n",
    "\n",
    "`get_slot_translations()` Take a scenario name as input (as in Exercise 3)\n",
    "\n",
    "You are not graded on the output of these methods, so don't worry if you had trouble with the previous exercises. The tests for this section will only try to call these functions to check if they exist and accept the appropriate input arguments. There is no test of the return value. You can actually return any truthy value that you want, and you don't actually have to write any real code inside these methods. Do not return a falsey value or `None`, as that will fail autotesting.\n",
    "\n",
    "### Magic methods\n",
    "\n",
    "`len(massive)` should return the number of languages that were loaded\n",
    "\n",
    "Two instances of this class are equal if they have the same set of languages and the same data split (test, train, validation, all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 - Test Driven Development\n",
    "rubric={accuracy:10, reasoning:10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Description\n",
    "For the last exercise, you'll take a 'test-driven development' (TDD) approach to designing a function. This exercise does not involve the MASSIVE dataset from earlier.\n",
    "\n",
    "You will design a function called `count_words()` which takes text as input, and return a dictionary containing the counts of every word in the text.\n",
    "\n",
    "### Testing\n",
    "You must write 5 unit tests for this function using `assert` statements. For each test, provide a short comment, one or two sentences, explaining the purpose of the test. In the spirit of TDD, you should start by writing these tests before coding up your function.\n",
    "\n",
    "### Signature\n",
    "\n",
    "`count_words(text: str, punctuation: iterable, ignore_case: bool) -> dict`\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `text`, string. The text to be analyzed. Required, no default value.\n",
    "- `punctuation`, iterable. This can be a string, or list of strings, containing punctuation symbols to remove from to the text. If a falsey value is passed, then all puncutation is retained. Required, no default value.\n",
    "- `ignore_case`, boolean. If `True`, all text is converted to lowercase. Default is `False`.\n",
    "\n",
    "\n",
    "### Return value\n",
    "The function returns a dictionary where keys are words from the text, and values represent how many times the words appeared in the text. Here are some examples of what the output would look like for different argument values (the order of the output dictionary doesn't matter)\n",
    "\n",
    "`text = 'The large cat chased the small cat.'`\n",
    "\n",
    "`print(count_words(text, punctuation=[], ignore_case=False))`\n",
    "\n",
    "`{'The': 1, 'large': 1, 'cat': 1, 'chased': 1, 'the': 1, 'small': 1, 'cat.': 1}`\n",
    "\n",
    "`print(count_words(text, punctuation='.', ignore_case=False))`\n",
    "\n",
    "`{'The': 1, 'large': 1, 'cat': 2, 'chased': 1, 'the': 1, 'small': 1}`\n",
    "\n",
    "`print(count_words(text, punctuation='.', ignore_case=True))`\n",
    "\n",
    "`{'the': 2, 'large': 1, 'cat': 2, 'chased': 1, 'small': 1}`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Challenge - the `os` module\n",
    "rubric={accuracy:5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Update the `load_massive()` function from exercise 1 to add a new `path` argument. This should be a string that represents a path to the MASSIVE language data files. Keep in mind that this argument is only a path to a directory. The specific languages to load are still provided by the `languages` argument. You will need to write some code that joins together the path and the language file names.\n",
    "\n",
    "You cannot solve this problem through regular string joining, because Windows and Mac systems have different ways of creating file paths. Windows uses a '\\' symbol (e.g. `C:\\Users\\Data\\french.csv`) while Mac uses '/' (e.g. `User/Data/french.csv'`). To make your code work across different operating systems, you'll need to look into Python's `os` module. It has a special join method for creating file paths, which can check the operating system and select the correct separator symbol. \n",
    "\n",
    "There are copies of the MASSIVE data sitting in a subdirectory called 'data/massive', which you can use for testing this new argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1_1": {
     "name": "q1_1",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> data = get_massive_data(['English', 'French'], split='train')\n>>> assert len(data) == 400, \"Data isn't split correctly\"\n>>> data = get_massive_data(['English'])\n>>> assert len(data) == 600, 'Default value for \"split\" not working correctly'\n>>> assert all(data.columns == ['language', 'text', 'annotation', 'scenario']), 'Missing or incorrect column name'\n>>> assert not any(data.columns != ['language', 'text', 'annotation', 'scenario']), 'There are extra columns in your dataframe'\n>>> assert pd.api.types.is_integer_dtype(data.index), 'ID column is not an integer'\n>>> data = get_massive_data(['Vietnamese'], split='train')\n>>> assert all(data), 'Vietnamese data is missing - did you use the helper function?'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_1": {
     "name": "q2_1",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> massive2 = get_massive_data(['English', 'French'], split='validation')\n>>> utterances = get_translations(massive2, 217, annotations=True)\n>>> assert utterances.loc['English'].annotation == 'is it [weather_descriptor : raining] outside'\n>>> assert utterances.loc['French'].annotation == \"est-ce qu'il [weather_descriptor : pleut] dehors\"\n>>> utterances = get_translations(massive2, 217)\n>>> assert utterances.loc['English'].text == 'is it raining outside'\n>>> assert utterances.loc['French'].text == \"est-ce qu'il pleut dehors\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_1": {
     "name": "q3_1",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> massive = get_massive_data(['English', 'French'], split='test')\n>>> slots = get_slot_translations(massive, 'iot')\n>>> assert slots.loc[8, 'color_type']['English'] == 'pink'\n>>> assert 'English' in slots.columns and 'French' in slots.columns\n>>> assert any(slots[slots['English'] == 'no slot'])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4_1": {
     "name": "q4_1",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert hasattr(Massive, 'all_languages')\n>>> massive = Massive(['English', 'French', 'German'], split='test')\n>>> assert hasattr(massive, 'data')\n>>> assert hasattr(massive, 'languages') and all((x in massive.languages for x in ['English', 'French', 'German']))\n>>> assert hasattr(massive, 'split') and massive.split == 'test'\n>>> assert hasattr(massive, 'get_translations') and massive.get_translations(17, annotations=False)\n>>> assert hasattr(massive, 'get_slot_translations') and massive.get_slot_translations('weather')\n>>> assert len(massive) == 3\n>>> german = Massive(['German'], split='test')\n>>> proto_germanic = Massive(['German'], split='validation')\n>>> deutch = Massive(['German'], split='test')\n>>> assert not german == massive\n>>> assert not german == proto_germanic\n>>> assert german == deutch\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e48f8b1687318edbd5a2a918b592db3baee1b5f69ffdc30179f0c7d8337e101b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
