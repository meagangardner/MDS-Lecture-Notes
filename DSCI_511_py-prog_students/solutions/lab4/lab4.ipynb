{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ASSIGNMENT CONFIG\n",
    "solutions_pdf: false\n",
    "export_cell: false\n",
    "check_all_cell: false\n",
    "environment: environment.yml\n",
    "generate:\n",
    "    pdf: false\n",
    "    zips: false\n",
    "    show_hidden: false\n",
    "    show_stdout: true\n",
    "files:\n",
    "    - English_massive_data.csv\n",
    "    - Vietnamese_massive_data.csv\n",
    "    - French_massive_data.csv     \n",
    "    - German_massive_data.csv     \n",
    "    - massive_dataframe.pkl\n",
    "    - Korean_massive_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Functions, Classes and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run this cell\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #pandas can get pretty verbose!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Quality\n",
    "rubric={quality:5}\n",
    "\n",
    "The code that you write for this assignment will be given one overall grade for code quality, see our code quality rubric as a guide to what we are looking for. Also, for this course (and other MDS courses that use R), we are trying to follow the PEP 8 code style. There is a guide you can refer too: https://peps.python.org/pep-0008/\n",
    "\n",
    "Each code question will also be assessed for code accuracy (i.e., does it do what it is supposed to do?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTRODUCTION\n",
    "\n",
    "In this lab, you'll be looking at a dataset called MASSIVE which contains ~1M sentences across 50 languages. It is a \"parallel corpus\", meaning that the same sentences appear in all languages. Two sentences with the same ID in different languages can be considered 'translations' of each other. (Strictly speaking they are not, they are each translations of the English sentence with that ID, but we can ignore that nuance for today.) \n",
    "\n",
    "Sentences are referred to as \"utterances\" in the context of MASSIVE, and they represent things that people would say to virtual assistants, such as \"set an alarm\", \"remind me to water my plants\", \"what time is my next appointment\", etc. Utterances are available as plain text, or with semantic annotation.\n",
    "\n",
    "You can examine the full dataset on HuggingFace here: https://huggingface.co/datasets/AmazonScience/massive\n",
    "\n",
    "To keep things manageable for the lab, we are using a slim version of MASSIVE consisting of just 5 languages with 600 utterances each: English, French, German, Korean, and Vietnamese. The data is available in 5 files named \"{language}_massive_data.csv\". For example you can load the English data like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>split</th>\n",
       "      <th>id</th>\n",
       "      <th>utt</th>\n",
       "      <th>annot_utt</th>\n",
       "      <th>scenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "      <td>wake me up at five am this week</td>\n",
       "      <td>wake me up at [time : five am] [date : this week]</td>\n",
       "      <td>alarm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>test</td>\n",
       "      <td>3</td>\n",
       "      <td>quiet</td>\n",
       "      <td>quiet</td>\n",
       "      <td>audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>pink is all we need</td>\n",
       "      <td>[color_type : pink] is all we need</td>\n",
       "      <td>iot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>test</td>\n",
       "      <td>14</td>\n",
       "      <td>and the darkness has fallen</td>\n",
       "      <td>and the darkness has fallen</td>\n",
       "      <td>iot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>test</td>\n",
       "      <td>19</td>\n",
       "      <td>olly turn the lights off in the bedroom</td>\n",
       "      <td>olly turn the lights off in the [house_place :...</td>\n",
       "      <td>iot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language split  id                                      utt  \\\n",
       "0  English  test   0          wake me up at five am this week   \n",
       "1  English  test   3                                    quiet   \n",
       "2  English  test   8                      pink is all we need   \n",
       "3  English  test  14              and the darkness has fallen   \n",
       "4  English  test  19  olly turn the lights off in the bedroom   \n",
       "\n",
       "                                           annot_utt scenario  \n",
       "0  wake me up at [time : five am] [date : this week]    alarm  \n",
       "1                                              quiet    audio  \n",
       "2                 [color_type : pink] is all we need      iot  \n",
       "3                        and the darkness has fallen      iot  \n",
       "4  olly turn the lights off in the [house_place :...      iot  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this cell\n",
    "english = pd.read_csv('english_massive_data.csv', encoding='utf-8')\n",
    "english.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each language file has the same 7 columns:\n",
    "- `language` is the name of a language\n",
    "- `split` Each language is split into 'train', 'test', and 'validation' sets. An utterance will only appear in one of these sets.\n",
    "- `id` is an utterance id. Within a language, each utterance has a unique id. Across languages, utterances will have the same id if they are 'translations' of each other.\n",
    "- `utt` Raw text of an utterance, written in the conventional orthography of a language\n",
    "- `annot_utt` An annotated version of the utterance, where some words may have semantic labels indicated by square brackets\n",
    "- `scenario` The general topic of the sentence (news, alarms, music, datetime, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: get_massive_data()\n",
    "rubric={autograde:12}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q1_1\n",
    "points: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6cd0b7f72a4c69db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Description\n",
    "\n",
    "Your first task is to write a new function that takes list of language names, and returns a single pandas dataframe with all the relevant data from the CSV files. Someone would be able to call your function like this:\n",
    "\n",
    "`massive = get_massive_data(languages=['English', 'French'], split='test')`\n",
    "\n",
    "Don't forget to write a docstring, explaining what your function does!\n",
    "\n",
    "### Signature\n",
    "\n",
    "`get_massive_data(languages: list, split_type: str) -> pandas.DataFrame`\n",
    "\n",
    "### Arguments\n",
    "\n",
    "`languages` is a list of languages. This argument is required and should not have a default value. \n",
    "\n",
    "`split_type` Options are 'test', 'train', 'validation', or 'all'. This argument is optional, and the default value should be 'all'.\n",
    "\n",
    "### Return value\n",
    "The function should return a pandas DataFrame. Use the utterance id as your index. Note that this will create non-unique indexes, since the same id values are used across languages.  Be sure to convert the id to an integer! \n",
    "\n",
    "The DataFrame should have these columns:\n",
    "\n",
    "<table>\n",
    "<tr><td>'language'</td>\t    <td>the name of a language (passed as part of the `languages` argument in this function)</td></tr>\n",
    "<tr><td>'text'</td>\t \t    <td>a natural language sentence (corresponds to the 'utt' column in MASSIVE)</td></tr>\n",
    "<tr><td>'annotation'</td> \t<td>the same sentence with semantic labelling on words (corresponds to the 'annot_utt' column in MASSIVE)</td></tr>\n",
    "<tr><td>'scenario'</td>\t    <td>a semantic label for a scenario (corresponds to 'scenario' column in MASSIVE)</td></tr>\n",
    "</table>\n",
    "\n",
    "For example, with English, French and German loaded, index 0 looks like this.\n",
    "<table>\n",
    "<tr><th>id</th>\t<th>language</th>\t<th>text</th>\t<th>annotation</th>\t<th>scenario</th></tr>\n",
    "\t\t\t\n",
    "<tr><td>0</td>\t<td>en-US</td>\t<td>wake me up at five am this week</td>\t<td>wake me up at [time : five am] [date : this week]</td>\t<td>alarm</td></tr>\n",
    "<tr><td>0</td>\t<td>fr-FR</td>\t<td>réveille-moi à cinq heures du matin cette semaine</td>\t<td>réveille-moi à [time : cinq heures du matin]</td> <td>alarm</td></tr>\n",
    "<tr><td>0</td>\t<td>de-DE</td>\t<td>wecke mich in dieser woche um fünf uhr auf</td>\t<td>wecke mich in [date : dieser woche] um [time :...</td>\t<td>alarm</td></tr>\n",
    "</table>\n",
    "\n",
    "### Hint\n",
    "Write a loop to load each dataset individually and then use panda's concatenate function\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def get_massive_data(languages, split='all'):\n",
    "    \"\"\"\n",
    "    Loads utterance data from the MASSIVE dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    languages : list\n",
    "        List of strings representing names of languages to load, e.g. \"German\", \"English\"\n",
    "    split : str\n",
    "        String representing which subst of data to load. Options are 'train', 'test', 'validation', and 'all'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame with five columns: 'id', 'language', 'text', 'annotation', and 'scenario'\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    massive_en_fre = get_massive_data(languages=['English', 'French'], split='test')\n",
    "    \"\"\"\n",
    "    dfs = list()\n",
    "    for language in languages:\n",
    "        lang_df = pd.read_csv(f'{language}_massive_data.csv', encoding='utf-8')\n",
    "        dfs.append(lang_df)\n",
    "    massive = pd.concat(dfs)\n",
    "    massive = massive.rename(columns = {'utt': 'text', 'annot_utt': 'annotation'})\n",
    "    if split != 'all':\n",
    "        massive = massive[massive['split'] == split]\n",
    "    massive = massive[['id', 'language', 'text', 'annotation', 'scenario']]\n",
    "    massive['id'] = massive['id'].astype(int)\n",
    "    massive = massive.set_index('id')\n",
    "    return massive\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "#Test that function returns splits correctly\n",
    "data = get_massive_data(['English', 'French'], split='train')\n",
    "assert len(data) == 400, 'Data isn\\'t split correctly'\n",
    "\n",
    "#Test that function returns all splits by default\n",
    "data = get_massive_data(['English'])\n",
    "assert len(data) == 600, 'Default value for \"split\" not working correctly'\n",
    "\n",
    "#Test that all columns are present\n",
    "assert all(data.columns == ['language', 'text', 'annotation', 'scenario']), 'Missing or incorrect column name'\n",
    "assert not(any(data.columns != ['language', 'text', 'annotation', 'scenario'])), 'There are extra columns in your dataframe'\n",
    "\n",
    "#Test that id is an integer\n",
    "assert pd.api.types.is_integer_dtype(data.index), 'ID column is not an integer'\n",
    "\n",
    "#Test that the helper function was not used \n",
    "data = get_massive_data(['Vietnamese'], split='train')\n",
    "assert all(data), 'Vietnamese data is missing - did you use the helper function?'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q1_2\n",
    "points: 5\n",
    "manual: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2: error handling for `get_massive_data()`\n",
    "rubric={accuracy: 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add code to the `get_massive_data()` function to handle incorrect language inputs, like 'zz-BB' or 'Navajo'. If a language name is not recognized, then the function should \"fail gracefully\". This means that instead of raising an error and stopping, it should skip over the incorrect name and keep processing the rest of the list. Before returning, your function should print a warning that contains all the languages that didn't work correctly. You can simply print this warning to screen with `print()`, you do not need to raise an actual Python Warning. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def get_massive_data(languages, split='all'):\n",
    "    \"\"\"\n",
    "    Loads utterance data from the MASSIVE dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    languages : list\n",
    "        List of strings representing names of languages to load, e.g. \"German\", \"English\"\n",
    "    split : str\n",
    "        String representing which subst of data to load. Options are 'train', 'test', 'validation', and 'all'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame with five columns: 'id', 'language', 'text', 'annotation', and 'scenario'\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    massive_en_fre = get_massive_data(languages=['English', 'French'], split='test')\n",
    "    \"\"\"\n",
    "    dfs = list()\n",
    "    warnings = list()\n",
    "    for language in languages:\n",
    "        try:\n",
    "            lang_df = pd.read_csv(f'{language}_massive_data.csv', encoding='utf-8')\n",
    "            dfs.append(lang_df)\n",
    "        except FileNotFoundError:\n",
    "            warnings.append(language)\n",
    "            continue\n",
    "    massive = pd.concat(dfs)\n",
    "    massive = massive.rename(columns = {'utt': 'text', 'annot_utt': 'annotation'})\n",
    "    if split != 'all':\n",
    "        massive = massive[massive['split'] == split]\n",
    "    massive = massive[['id', 'language', 'text', 'annotation', 'scenario']]\n",
    "    massive['id'] = massive['id'].astype(int)\n",
    "    massive = massive.set_index('id')\n",
    "    if warnings:\n",
    "        print('The following languages were not found: ', ', '.join(warnings))\n",
    "    return massive\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HELPER CELL\n",
    "#If you were not able to complete Exercise 1, then you can use the following function as a replacement for the rest of the lab. \n",
    "#Just uncomment the code and run the cell.\n",
    "#It returns a correctly formatted DataFrame object that you can use. \n",
    "#Note that it only returns 3 languages: English, French, and German. This is enough to pass all subsequent exercises.\n",
    "\n",
    "# import pickle\n",
    "# def get_massive_data(languages, split):\n",
    "#     with open('massive_dataframe.pkl', mode='rb') as f:\n",
    "#         massive = pickle.load(f)\n",
    "#     return massive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: get_translations()\n",
    "rubric={autograde:12}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q2_1\n",
    "points: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "Now that you have MASSIVE formated as a dataframe, your next task is to write a search function that takes an utterance id, and returns all the translations of that utterance. For example, to get the translations for utterance 17 we could do this:\n",
    "\n",
    "```\n",
    "languages = ['English', 'Korean']\n",
    "massive = get_massive_data(languages)\n",
    "utterance_17 = get_translations(massive, 17)\n",
    "```\n",
    "\n",
    "Don't forget to add a docstring to this function, explaining what it does.\n",
    "\n",
    "### Signature\n",
    "\n",
    "`get_translations(massive: pd.DataFrame, utterance_id: int, annotations: bool) -> pandas.DataFrame`\n",
    "\n",
    "### Arguments\n",
    "\n",
    "`massive` is a DataFrame containing MASSIVE data. Ideally this should be the output of your `get_massive_data` function. However, if you were unable to pass all of the tests, you can run the \"helper cell\" below which get a properly formatted DataFrame for you.\n",
    "\n",
    "`utterance_id` is an integer representing an utterance id\n",
    "\n",
    "`annotations` is a boolean. If True, the function return values from the 'annotations' column, if False then it return values from the 'text' column. The default is False.\n",
    "\n",
    "### Return value\n",
    "This returns a DataFrame where rows are indexed by language, and there is one column called either 'text' or 'annotation' (depending on the argument supplied to the function).\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def get_translations(massive, utterance_id, annotations=False):\n",
    "    \"\"\"\n",
    "    Finds utterances in MASSIVE that share an utterance id. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    massive : pd.DataFrame\n",
    "        DataFrame with utterance data from MASSIVE\n",
    "    utterance_id : int\n",
    "        Integer representing the utterance id to fetch\n",
    "    annotations : bool\n",
    "        If True, retur0ns text with semantic annotations, if False retuns plain text\n",
    "    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame with one column 'annotation' or 'text', depending on the value of the annotations parameter\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    utterance_107 = get_translations(massive, 107)\n",
    "    \"\"\"\n",
    "    rows = massive.loc[utterance_id]\n",
    "    rows = rows.set_index('language')\n",
    "    return_type = 'annotation' if annotations else 'text'\n",
    "    return rows[[return_type]]\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "massive2 = get_massive_data(['English', 'French'], split='validation')\n",
    "\n",
    "#Test that function returns the correct data\n",
    "utterances = get_translations(massive2, 217, annotations=True)\n",
    "assert utterances.loc['English'].annotation == \"is it [weather_descriptor : raining] outside\"\n",
    "assert utterances.loc['French'].annotation == \"est-ce qu'il [weather_descriptor : pleut] dehors\"\n",
    "\n",
    "#Test that annotations is set to False by default\n",
    "utterances = get_translations(massive2, 217)\n",
    "assert utterances.loc['English'].text == 'is it raining outside'\n",
    "assert utterances.loc['French'].text == \"est-ce qu'il pleut dehors\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 2.1: error handling for get_translations()\n",
    "rubric = {accuracy: 5}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q2_1\n",
    "points: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the `get_translations()` function to handle invalid utterance IDs. If an invalid ID is passed, then the function should return an empty dictionary."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "def get_translations(massive, utterance_id, annotations=False):\n",
    "    \"\"\"\n",
    "    Finds utterances in MASSIVE that share an utterance id.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    massive : pd.DataFrame\n",
    "        DataFrame with utterance data from MASSIVE\n",
    "    utterance_id : int\n",
    "        Integer representing the utterance id to fetch\n",
    "    annotations : bool\n",
    "        If True, retur0ns text with semantic annotations, if False retuns plain text\n",
    "    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame with one column 'annotation' or 'text', depending on the value of the annotations parameter\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "   utterance_107 = get_translations(massive, 107)\n",
    "    \"\"\"     \n",
    "  \n",
    "    try:\n",
    "        rows = massive.loc[utterance_id]\n",
    "    except KeyError:\n",
    "        return {}\n",
    "    rows = rows.set_index('language')\n",
    "    return_type = 'annotation' if annotations else 'text'\n",
    "    return rows[[return_type]]\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE 3: get_slot_translations()\n",
    "rubric={autograder:12}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q3_1\n",
    "points: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "The utterances in MASSIVE have two kinds of semantic labels: a \"scenario\", which is the general topic of the whole utterance, and \"slots\", which are specific words or phrases. Scenarios have their own column in the data. Slots have to be extracted from the text in the \"annotations\" column, where are they are indicated by square brackets.\n",
    "\n",
    "For example, utterance 7 in the 'audio' scenario has this annotation:\n",
    "\n",
    "`pause for [time : ten seconds]\t`\n",
    "\n",
    "This means the slot named 'time' has a value of 'ten seconds'. The slot names are always in English. Utterance 7 in fr-FR is annotated like this:\n",
    "\n",
    "`pause pendant [time : dix secondes]`\n",
    "\n",
    "For this exercise, you'll write a function that takes a scenario as input, and returns a table of translations for each slot in each utterance in that scenario. Extracting the slot values requires using regular expressions, which we didn't cover during class, so the code for creating a `slot_name` and `slot_value` column is included in the solution for you. \n",
    "\n",
    "Someone would be able to use your function like this:\n",
    "\n",
    "```\n",
    "massive = get_massive_data(['English', 'French'])\n",
    "audio_slots = get_slot_translations(massive, 'audio')\n",
    "```\n",
    "\n",
    "Don't forget to add a docstring to your function, explaining what it does.\n",
    "\n",
    "### Signature\n",
    "`get_slot_translations(massive: pd.DataFrame, scenario: str) -> pd.DataFrame`\n",
    "\n",
    "\n",
    "### Arguments\n",
    "`massive` a pandas dataframe with MASSIVE data. Required, no default value.\n",
    "\n",
    "`scenario` a string representing one of the scenarios in MASSIVE. Required, no default value.\n",
    "\n",
    "### Return value\n",
    "A dataframe indexed by utterance id. The first column is called 'slot_name', and the remaining columns show translations of that slot for each language passed into the function. Some utterances in MASSIVE don't have any slots. Fill any missing values with the string 'no slots'. \n",
    "\n",
    "For example, if this function were called with the English, French and German languages in the 'takeaway' scenario, the head of the output table would look like this:\n",
    "\n",
    "<table>\n",
    "    <tr><th>id</th><th>slot_name</th><th>English</th><th>French</th><th>German</th></tr>\n",
    "    <tr><td>51</td><td>order_type</td><td>delivery</td><td>livraison</td><td>lieferoptionen</td></tr>\n",
    "    <tr><td>52</td><td>time</td><td>delivery</td><td>livraison</td><td>liefer</td></tr>\n",
    "    <tr><td>53</td><td>time</td><td>delivery</td><td>livraison</td><td>liefer</td></tr>\n",
    "    <tr><td>54</td><td>time</td><td>delivery</td><td>livraison</td><td>liefer</td></tr>\n",
    "    <tr><td>55</td><td>food_type</td><td>curry</td><td>piment</td><td>curry</td></tr>\n",
    "</table>\n",
    "\n",
    "### Hint\n",
    "There is already code provided for you to add the `slot_value` and `slot_name` columns to your table. You need to reshape the data into the correct format."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slot_translations(massive, scenario_name):\n",
    "  #---Don't delete these line! This code finds the necessary slots for you and adds them to the dataframe\n",
    "  pattern = r'\\[([^:\\[\\]]+) : ([^\\[\\]]+)\\]' \n",
    "  massive[['slot_name', 'slot_value']] = massive['annotation'].str.extract(pattern) \n",
    "  #---\n",
    "  # BEGIN SOLUTION\n",
    "  df = massive[ massive['scenario'] == scenario_name ]\n",
    "  df = df[['language', 'slot_name', 'slot_value']]\n",
    "  df = df.fillna('no slots')\n",
    "  df = df.reset_index()\n",
    "  df.rename(columns={'index':'id'})\n",
    "  df = df.pivot(index=['id', 'slot_name'], columns='language', values='slot_value').reset_index()\n",
    "  df.set_index(['id', 'slot_name'], inplace=True)\n",
    "  df = df.fillna('no slots')\n",
    "  return df\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "massive = get_massive_data(['English', 'French'], split='test')\n",
    "slots = get_slot_translations(massive, 'iot')\n",
    "\n",
    "#Test that function returns correct slots\n",
    "assert slots.loc[(8, 'color_type')]['English'] == 'pink'\n",
    "\n",
    "#Test that function has correct column labels\n",
    "assert 'English' in slots.columns and 'French' in slots.columns\n",
    "\n",
    "#Test that empty celled were filled\n",
    "assert any(slots[ slots['English'] == 'no slot'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Massive class\n",
    "rubric={autograder:10}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q4_1\n",
    "points: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that's a little awkward about our functions so far is that we have to \"repeat\" the massive variable and pass it around\n",
    "\n",
    "```\n",
    "massive = get_massive_data(['Korean', 'German'], split='test')\n",
    "utt_123 = get_translations(massive, 123)\n",
    "weather_slots = get_slot_translations(massive, 'weather')\n",
    "```\n",
    "\n",
    "For this last exercise, you'll define a Massive object, which contains all these functions, and which can remember the languages. The code above would run this like this instead:\n",
    "\n",
    "```\n",
    "massive = Massive(['Korean', 'German'], split='test')\n",
    "utt_123 = massive.get_translations(123)\n",
    "weather_slots = massive.get_slot_translation('weather')\n",
    "```\n",
    "\n",
    "Don't worry if you didn't pass all the tests in earlier exercises. Your grade in this section depends on your ablity to organize code into a class, and you won't be double-graded on the output of any previous function.\n",
    "\n",
    "Don't forget to add a doctstring to your class, explaining what it does, and listing out methods and attributes.\n",
    "\n",
    "### Instance attributes\n",
    "\n",
    "`.languages` A list of strings representing language names\n",
    "\n",
    "`.split` One of 'test', 'train', 'validation', 'all'\n",
    "\n",
    "`.data`  A pandas dataframe\n",
    "\n",
    "### Class attributes\n",
    "\n",
    "`.all_languages` A list of strings representing all languages for which we have data\n",
    "\n",
    "### Methods\n",
    "\n",
    "`get_translations()` Takes an utterance id and 'annotations' boolean as input (as in Exercise 2).\n",
    "\n",
    "`get_slot_translations()` Take a scenario name as input (as in Exercise 3)\n",
    "\n",
    "You are not graded on the output of these methods, so don't worry if you had trouble with the previous exercises. The tests for this section will only try to call these functions to check if they exist and accept the appropriate input arguments. There is no test of the return value. You can actually return any truthy value that you want, and you don't actually have to write any real code inside these methods. Do not return a falsey value or `None`, as that will fail autotesting.\n",
    "\n",
    "### Magic methods\n",
    "\n",
    "`len(massive)` should return the number of languages that were loaded\n",
    "\n",
    "Two instances of this class are equal if they have the same set of languages and the same data split (test, train, validation, all)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "class Massive:\n",
    "    all_languages = ['English', 'French', 'German', 'Vietnamese', 'Korean']\n",
    "\n",
    "    def __init__(self, languages, split):\n",
    "        self.languages = languages\n",
    "        self.split = split\n",
    "        self.data = pd.DataFrame()\n",
    "        #this is where massive data would actually get loaded\n",
    "    \n",
    "    def get_translations(self, utterance_id, annotations=False):\n",
    "        return utterance_id\n",
    "\n",
    "    def get_slot_translations(self, scenario):\n",
    "        return scenario\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.languages)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.languages == other.languages) and (self.split == other.split)\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Massive at 0x134a9e0d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "german = Massive(['German'], split='test')\n",
    "german"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "#Test for class attribute\n",
    "assert hasattr(Massive, 'all_languages')\n",
    "\n",
    "#Instance testing\n",
    "massive = Massive(['English', 'French', 'German'], split='test')\n",
    "\n",
    "#Test for attributes\n",
    "assert hasattr(massive, 'data')\n",
    "assert hasattr(massive, 'languages') and all(x in massive.languages for x in ['English', 'French', 'German'])\n",
    "assert hasattr(massive, 'split') and massive.split == 'test'\n",
    "\n",
    "#Test for existence of methods\n",
    "assert hasattr(massive, 'get_translations') and massive.get_translations(17, annotations=False)\n",
    "assert hasattr(massive, 'get_slot_translations') and massive.get_slot_translations('weather')\n",
    "\n",
    "#Test for __len__\n",
    "assert len(massive) == 3\n",
    "\n",
    "#Test for equality\n",
    "german = Massive(['German'], split='test')\n",
    "proto_germanic = Massive(['German'], split='validation')\n",
    "deutch = Massive(['German'], split='test')\n",
    "assert not german == massive\n",
    "assert not german == proto_germanic\n",
    "assert german == deutch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END TESTS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 - Test Driven Development\n",
    "rubric={accuracy:10, reasoning:10}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q5_1\n",
    "points: 10\n",
    "manual: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "For the last exercise, you'll take a 'test-driven development' (TDD) approach to designing a function. This exercise does not involve the MASSIVE dataset from earlier.\n",
    "\n",
    "You will design a function called `count_words()` which takes text as input, and return a dictionary containing the counts of every word in the text.\n",
    "\n",
    "### Testing\n",
    "You must write 5 unit tests for this function using `assert` statements. For each test, provide a short comment, one or two sentences, explaining the purpose of the test. In the spirit of TDD, you should start by writing these tests before coding up your function.\n",
    "\n",
    "### Signature\n",
    "\n",
    "`count_words(text: str, punctuation: iterable, ignore_case: bool) -> dict`\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `text`, string. The text to be analyzed. Required, no default value.\n",
    "- `punctuation`, iterable. This can be a string, or list of strings, containing punctuation symbols to remove from to the text. If a falsey value is passed, then all puncutation is retained. Required, no default value.\n",
    "- `ignore_case`, boolean. If `True`, all text is converted to lowercase. Default is `False`.\n",
    "\n",
    "\n",
    "### Return value\n",
    "The function returns a dictionary where keys are words from the text, and values represent how many times the words appeared in the text. Here are some examples of what the output would look like for different argument values (the order of the output dictionary doesn't matter)\n",
    "\n",
    "`text = 'The large cat chased the small cat.'`\n",
    "\n",
    "`print(count_words(text, punctuation=[], ignore_case=False))`\n",
    "\n",
    "`{'The': 1, 'large': 1, 'cat': 1, 'chased': 1, 'the': 1, 'small': 1, 'cat.': 1}`\n",
    "\n",
    "`print(count_words(text, punctuation='.', ignore_case=False))`\n",
    "\n",
    "`{'The': 1, 'large': 1, 'cat': 2, 'chased': 1, 'the': 1, 'small': 1}`\n",
    "\n",
    "`print(count_words(text, punctuation='.', ignore_case=True))`\n",
    "\n",
    "`{'the': 2, 'large': 1, 'cat': 2, 'chased': 1, 'small': 1}`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "count_words() missing 1 required positional argument: 'punctuation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m             counts[w] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m counts\n\u001b[0;32m---> 35\u001b[0m \u001b[43mcount_words\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# END SOLUTION\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: count_words() missing 1 required positional argument: 'punctuation'"
     ]
    }
   ],
   "source": [
    "# BEGIN SOLUTION\n",
    "def count_words(text, punctuation, ignore_case=False):\n",
    "    \"\"\"\n",
    "    Return counts of word types in a text\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        DataFrame with utterance data from MASSIVE\n",
    "    punctuation : iterable\n",
    "        String or list of punctuation symbols to ignore\n",
    "    ignore_case : bool\n",
    "        If True then case is ignored when comparing words to count\n",
    "    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary where keys are words from the text, and values are counts of those words.\n",
    "    \"\"\"\n",
    "    \n",
    "    if ignore_case:\n",
    "        text = text.lower()\n",
    "    if punctuation:\n",
    "        for p in punctuation:\n",
    "            text = text.replace(p, '')\n",
    "    words = text.split(' ')\n",
    "    counts = dict()\n",
    "    for w in words:\n",
    "        if w in counts:\n",
    "            counts[w] = counts[w] + 1\n",
    "        else:\n",
    "            counts[w] = 1\n",
    "    return counts\n",
    "\n",
    "count_words('')\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEGIN SOLUTION\n",
    "text = 'The large cat chased the small cat.'\n",
    "\n",
    "# 1. Test the function without a `puncutation` argument\n",
    "count = count_words(text, punctuation=[])\n",
    "assert 'cat.' in count\n",
    "\n",
    "# 2. Test the function with a `puncutation` argument\n",
    "count = count_words(text, punctuation='.')\n",
    "assert count['cat'] == 2\n",
    "\n",
    "# 3. Test the function when `ignore_case` is True\n",
    "count = count_words(text, punctuation=[], ignore_case=True)\n",
    "assert count['the'] == 2\n",
    "\n",
    "# 4. Test the function when `ignore_case` is False\n",
    "count = count_words(text, punctuation=[], ignore_case=False)\n",
    "assert 'The' in count\n",
    "\n",
    "# 5. Test the return value and make sure the count is accurate.\n",
    "count = count_words(text, punctuation='.', ignore_case=True)\n",
    "assert count == {'the': 2, 'large': 1, 'cat': 2, 'chased': 1, 'small': 1}\n",
    "\n",
    "# 6. Test that puncutation accepts any falsey value, and not just empty iterables\n",
    "count = count_words(text, punctuation=None)\n",
    "assert 'cat.' in count\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge - the `os` module\n",
    "rubric={accuracy:5}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# BEGIN QUESTION\n",
    "name: q6_1\n",
    "points: 5\n",
    "manual: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the `load_massive()` function from exercise 1 to add a new `path` argument. This should be a string that represents a path to the MASSIVE language data files. Keep in mind that this argument is only a path to a directory. The specific languages to load are still provided by the `languages` argument. You will need to write some code that joins together the path and the language file names.\n",
    "\n",
    "You cannot solve this problem through regular string joining, because Windows and Mac systems have different ways of creating file paths. Windows uses a '\\' symbol (e.g. `C:\\Users\\Data\\french.csv`) while Mac uses '/' (e.g. `User/Data/french.csv'`). To make your code work across different operating systems, you'll need to look into Python's `os` module. It has a special join method for creating file paths, which can check the operating system and select the correct separator symbol. \n",
    "\n",
    "There are copies of the MASSIVE data sitting in a subdirectory called 'data/massive', which you can use for testing this new argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# BEGIN SOLUTION\n",
    "def get_massive_data(languages, split='all', path=None):\n",
    "    dfs = list()\n",
    "    for language in languages:\n",
    "        if path:\n",
    "            file = os.path.join(path, f'{language}_massive_data.csv')\n",
    "        lang_df = pd.read_csv(file, encoding='utf-8')\n",
    "        dfs.append(lang_df)\n",
    "    massive = pd.concat(dfs)\n",
    "    massive = massive.rename(columns = {'utt': 'text', 'annot_utt': 'annotation'})\n",
    "    if split != 'all':\n",
    "        massive = massive[massive['split'] == split]\n",
    "    massive = massive[['id', 'language', 'text', 'annotation', 'scenario']]\n",
    "    massive['id'] = massive['id'].astype(int)\n",
    "    massive = massive.set_index('id')\n",
    "    return massive\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# END QUESTION"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e48f8b1687318edbd5a2a918b592db3baee1b5f69ffdc30179f0c7d8337e101b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
