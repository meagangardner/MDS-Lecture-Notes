{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/dsci511_header.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Advanced data wrangling with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "rubric={mechanics:5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check off that you have read and followed each of these instructions:\n",
    "\n",
    "- [ ] All files necessary to run your work must be pushed to your GitHub.ubc.ca repository for this lab.\n",
    "- [ ] You need to have a minimum of 3 commit messages associated with your GitHub.ubc.ca repository for this lab.\n",
    "- [ ] You must also submit `.ipynb` file and the rendered PDF in this worksheet/lab to Gradescope. Entire notebook must be executed so the TA's can see the results of your work. \n",
    "- [ ] **There is autograding in this lab, so please do not move or rename this file. Also, do not copy and paste cells, if you need to add new cells, create new cells via the \"Insert a cell below\" button instead.**\n",
    "- [ ] To ensure you do not break the autograder remove all code for installing packages (i.e., DO NOT have `! conda install ...` or `! pip install ...` in your homework!\n",
    "- [ ] Follow the [MDS general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).\n",
    "- [ ] <mark>This lab has hidden tests. In this lab, the visible tests are just there to ensure you create an object with the correct name. The remaining tests are hidden intentionally. This is so you get practice deciding when you have written the correct code and created the correct data object. This is a necessary skill for data scientists, and if we were to provide robust visible tests for all questions you would not develop this skill, or at least not to its full potential.</mark>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Quality\n",
    "rubric={quality:5}\n",
    "\n",
    "The code that you write for this assignment will be given one overall grade for code quality, see our code quality rubric as a guide to what we are looking for. Also, for this course (and other MDS courses that use R), we are trying to follow the PEP 8 code style. There is a guide you can refer too: https://peps.python.org/pep-0008/\n",
    "\n",
    "Each code question will also be assessed for code accuracy (i.e., does it do what it is supposed to do?).\n",
    "\n",
    "## Writing \n",
    "rubric={writing:5}\n",
    "\n",
    "To get the marks for this writing component, you should:\n",
    "\n",
    "- Use proper English, spelling, and grammar throughout your submission (the non-coding parts).\n",
    "- Be succinct. This means being specific about what you want to communicate, without being superfluous.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!\n",
    "\n",
    "Run the cell below to load the packages needed for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import re\n",
    "from palmerpenguins import load_penguins # penguins data set for exercise 3\n",
    "from nycflights13 import flights # flights data set for exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Exercise 1: Working with dates\n",
    "\n",
    "rubric={autograde:16}\n",
    "\r",
    "In our recent past, we experienced the COVID-19 global pandemic. \n",
    "With your new data science skills, you can start to look at \n",
    "and visualize the data about this impactful pandemic yourself. \n",
    "Let's look at cumulative confirmed cases in British Columbia \n",
    "over a 3 month period from 2021/06/10 to 2021/09/10 \n",
    "(it was a peak COVID  season then). \n",
    "We can obtain such data from the [COVID-19 Data Repository by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University](https://github.com/CSSEGISandData/COVID-19).\r",
    "\r",
    "In particular, use Python to load the `time_series_covid19_confirmed_global.csv` file located at the url: [https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv](https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv).\r",
    "\r",
    "Then you will need to filter teses global data for records from the province of British Columbia \n",
    "during the time interval 2021/06/10 to 2021/09/10. Note that, you might need to tidy the data before you filter the time interval.  \n",
    "We provide you data visualization code, \n",
    "however your task is to ensure the dataframe is suitable for visualization. \n",
    "\n",
    "The final data set for data visualization should be named `bc_covid19_confirmed_3_months` \n",
    "and have only the following two columns: \r",
    "- one named `date`, whose `dtype` should be `Date`\r",
    "- one named `confirmed_cases`, whose `dtype` should be intt64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    "time_series_covid19_confirmed_global = None\n",
    "three_months = None\n",
    "bc_covid19_confirmed_3_months = None\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "bc_covid19_confirmed_3_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"ex1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s now visualize how cases have changed over the last three months in British Columbia by viewing cumulative cases per day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_months_BC = alt.Chart(bc_covid19_confirmed_3_months).mark_bar(color='lightblue').encode(\n",
    "    x=alt.X('date:T', title='2021'),  # Specify type as Temporal for dates\n",
    "    y=alt.Y('confirmed_cases:Q', title='Cumulative COVID-19 cases')\n",
    ").properties(\n",
    "    title='BC COVID-19 cases started to increase more rapidly in August and September of 2021'\n",
    ").configure_axis(\n",
    "    grid=False\n",
    ").configure_view(\n",
    "    strokeWidth=0\n",
    ")\n",
    "\n",
    "three_months_BC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Exercise 2: Working with strings\n",
    "\n",
    "rubric={accuracy:16}\r",
    "\r",
    "You have learned about string operations combined with regular expressions.    \r",
    "Now you are ready to apply them to the real world of data cleaning!    \r",
    "\r",
    "Your goal is to load in \"dirty Gapminder\" as a dataframe called `dirty` and \"clean Gapminder\" as a dataframe called `clean`, and wrangle `dirty` until it is the same as `clean`:\n",
    "- Dirty Gapminder: <https://raw.githubusercontent.com/STAT545-UBC/STAT545-UBC.github.io/master/gapminderDataFiveYear_dirty.txt>\n",
    "- Clean Gapminder: <https://raw.githubusercontent.com/STAT545-UBC/STAT545-UBC.github.io/master/gapminderDataFiveYear.txt>\n",
    "\n",
    "A test has been provided to check that `dirty` is the same as `clean`. Things you might want to do to clean up `dirty`:\n",
    "\n",
    "- Check that `dirty` and `clean` have the same columns;\n",
    "- Check if there is any missing data, if there is missing data (NaNs or empty strings) fill them with sensible values;\n",
    "- Check for things like capitalization, spelling, etc;\n",
    "- There may be entries that appear to have the exact same spelling and capitalization in both `dirty` and `clean`, but still don't match... Extra whitespace is often a frustrating (and invisible) problem when wrangling text data. You can use `Series.str.strip()` to trim any additional unwanted whitespace around a string.\n",
    "- At any time, you can check which rows in `dirty` are not equal to `clean` using something like: `dirty[dirty.ne(clean).any(axis=1)]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_dirty = 'https://raw.githubusercontent.com/STAT545-UBC/STAT545-UBC.github.io/master/gapminderDataFiveYear_dirty.txt'\n",
    "url_clean = 'https://raw.githubusercontent.com/STAT545-UBC/STAT545-UBC.github.io/master/gapminderDataFiveYear.txt'\n",
    "dirty = None\n",
    "clean = None\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"ex2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Exercise 3: Taking control of your categoricals\n",
    "rubric={accuracy:8,reasoning:8}\r",
    "\r",
    "Explore the effects of the `pandas` `sort_values` method on the `pandas` `categorical` `dtype`. Does sorting the values of a pandas categorical column in a data frame have any effect on, say, an `altair` figure? What about the `cat.reorder_categories` method? This exploration must involve the data, the categorical's order, and some figures, as well as a written explanation of what you are doing and what you find. Choose any data set you wish to demonstrate this. We provide code for a scatter plot figure you could modify for your data set to help you out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the penguins dataset\n",
    "penguins = load_penguins()\n",
    "\n",
    "# Convert the 'species' column to a categorical type\n",
    "penguins['species'] = pd.Categorical(penguins['species'])\n",
    "\n",
    "# Create the Altair chart\n",
    "penguins_chart = alt.Chart(penguins).mark_point(size=60).encode(\n",
    "    x=alt.X('bill_length_mm', title='Bill length (mm)'),\n",
    "    y=alt.Y('body_mass_g', title='Body mass (g)'),\n",
    "    color=alt.Color('species', scale=alt.Scale(scheme='category10'))\n",
    ").properties(\n",
    "    width=450,\n",
    "    height=350\n",
    ").configure_axis(\n",
    "    labelFontSize=14,\n",
    "    titleFontSize=18\n",
    ").configure_legend(\n",
    "    labelFontSize=14,\n",
    "    titleFontSize=18\n",
    ")\n",
    "\n",
    "penguins_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Exercise 4: Two table joins cheatsheet\n",
    "rubric={accuracy:8,reasoning:8}\n",
    "\n",
    "This exercise is to help you familiarize with the different _joins_ available in `pandas` using the `merge` method. First, take a look at [Jenny Bryan's cheatsheet](http://stat545.com/bit001_dplyr-cheatsheet.html). Your task is to create your own cheatsheet, covering all the joins that Jenny covers (and in both orders for joins where order has an effect) but focused on something you care about. Examples:\r",
    "\r",
    "  - Pets I have owned + breed + friendly vs. unfriendly + ??. Join to a table of pet breed, including variables for furry vs not furry, mammal true or false, etc.\r",
    "  - Movies and studios....\r",
    "  - Athletes and teams....\r",
    "\r",
    "The data set should be tractable (think 5-7 items in each table). **You are expected to create your own data set for this question, do not use an existing data set.**\r",
    "\r",
    "While demonstrating the joins with your data and code, also provide a narrative in written English explaining what you are doing and what is revealed through the joins. The narrative should be ~ 2-4 sentences per join scenario. **This narrative must be in your own words.**\r",
    "\r",
    "You will likely need to iterate between your data prep and your joining to make your explorations comprehensive and interesting. For example, you will want a specific amount (or lack) of overlap between the two data frames, in order to demonstrate all the different joins. You will want both the data frames to be as small as possible, while still retaining the expository value.\r",
    "\r",
    "You should create this cheatsheet as a separate `.ipynb` file that you render to `.md` (you can do that by clicking **File** > **Save and Export Notebook As ...** > **Markdown**). Both of these files should live in this lab2 repo, and you should paste the links (URL) to them below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Exercise 5: Grouping and aggregating\n",
    "\n",
    "rubric={autograde:16}\n",
    "\n",
    "Use the `pandas`to take the `flights` data set, from the `nycflights13` Python package, \n",
    "and obtain the average speed (in km/hr) and average distance (in km) for all flights, \n",
    "for each of the carriers AA, AS, UA and US.\n",
    "Name these new columns `carrier_avg_speed` and `carrier_avg_distance_km`, \n",
    "and round the values so that the answer is a whole number (i.e., no decimal points). \n",
    "Convert the carrier acronyms to their full names \n",
    "(American Airlines, Alaska Airlines, United Airlines and US Airways). \n",
    "Sort the results in ascending order according to `carrier_avg_speed`. \n",
    "Name the data frame `carrier_avg_flights`.\n",
    "\n",
    "Some hints:\n",
    "- The distance is in miles and air time is in minutes in the `flights` data. \n",
    "- You will have to create a column that holds the average speed for each flight before you can do this for each carrier.\n",
    "- You may also need to handle `NA` entries in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "carrier_avg_flights = None\n",
    "\n",
    "...\n",
    "carrier_avg_flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The tests below only check that the object has the correct names. The other tests are intentionally hidden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"ex5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Exercise 6: CHALLENGING\n",
    "rubric={accuracy:5}\n",
    "\n",
    "Warning: This exercise is challenging and could be time-consuming. Please only attempt if you find yourself finishing the assignment early and you want a bit more of a challenge.\n",
    "\n",
    "In this exercise, you will need to use regular expressions and the Python `re` library to parse a text file containing a collection of 10 \"Nigerian\" Fraud Letters, dating from 1998 to 2007. This is a subset of a data set [retrieved from Kaggle](https://www.kaggle.com/datasets/rtatman/fraudulent-email-corpus?resource=download).\n",
    "\n",
    "We would like you to create a dataframe with the following columns:\n",
    "- `senders` (containing the email addresses the emails were sent to)\n",
    "- `recipients` (containing the email addresses the emails were sent from)\n",
    "\n",
    "In the code below, we have read in the text file for you as a single string. \n",
    "\n",
    "Some useful resources:\n",
    "- You can test out your regex expression in real-time using https://regex101.com \n",
    "- Documentation on regex flags https://docs.python.org/3/library/re.html#flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the test_emails.txt file in read mode and read its contents into a string\n",
    "with open('data/test_emails.txt', 'r') as file:\n",
    "    email_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Congratulations!!!** You are done the lab!!! Pat yourself on the back, and submit your lab to **GitHub** and Gradescope! Make sure you have 3 Git commits!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "ex1": {
     "name": "ex1",
     "points": 16,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert bc_covid19_confirmed_3_months is not None, \"The DataFrame 'bc_covid19_confirmed_3_months' is not defined.\"\n>>> expected_columns = ['date', 'confirmed_cases']\n>>> assert list(bc_covid19_confirmed_3_months.columns) == expected_columns, f'Column names are incorrect. Expected: {expected_columns}, but got: {list(bc_covid19_confirmed_3_months.columns)}.'\n>>> assert not bc_covid19_confirmed_3_months.empty, \"The DataFrame 'bc_covid19_confirmed_3_months' is empty.\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "ex2": {
     "name": "ex2",
     "points": 16,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> clean = pd.read_csv(url_clean, delimiter='\\t')\n>>> assert dirty.equals(clean)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "ex5": {
     "name": "ex5",
     "points": 16,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert carrier_avg_flights is not None, \"The DataFrame 'carrier_avg_flights' is not defined.\"\n>>> expected_columns = ['carrier', 'carrier_avg_speed', 'carrier_avg_distance_km']\n>>> assert list(carrier_avg_flights.columns) == expected_columns, f'Column names are incorrect. Expected: {expected_columns}, but got: {list(carrier_avg_flights.columns)}.'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "e48f8b1687318edbd5a2a918b592db3baee1b5f69ffdc30179f0c7d8337e101b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
